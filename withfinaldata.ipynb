{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare(df):\n",
    "    global json_cols\n",
    "    global train_dict\n",
    "\n",
    "    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n",
    "    df['release_year'] = df['release_year']\n",
    "    df.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n",
    "    df.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n",
    "    \n",
    "    releaseDate = pd.to_datetime(df['release_date']) \n",
    "    df['release_dayofweek'] = releaseDate.dt.dayofweek \n",
    "    df['release_quarter'] = releaseDate.dt.quarter     \n",
    "    \n",
    "    rating_na = df.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\n",
    "    df[df.rating.isna()]['rating'] = df.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
    "    vote_count_na = df.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\n",
    "    df[df.totalVotes.isna()]['totalVotes'] = df.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
    "    #df['rating'] = df['rating'].fillna(1.5)\n",
    "    #df['totalVotes'] = df['totalVotes'].fillna(6)\n",
    "    df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) / ( df['totalVotes'] + 1000 )\n",
    "\n",
    "\n",
    "    df['originalBudget'] = df['budget']\n",
    "    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
    "    df['budget'] = np.log1p(df['budget']) \n",
    "    \n",
    "    \n",
    "    # Thanks to this Kernel for the next 7 features https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n",
    "    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(df['_collection_name'].fillna('')))\n",
    "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
    "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "    \n",
    "    \n",
    "    df['_popularity_mean_year'] = df['popularity'] / df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
    "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
    "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
    "    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n",
    "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
    "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
    "\n",
    "    df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n",
    "    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n",
    "    df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n",
    "    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n",
    "    df['_budget_rating_ratio'] = df['budget']/df['rating']\n",
    "    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n",
    "    df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n",
    "    \n",
    "    df['has_homepage'] = 1\n",
    "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n",
    "    \n",
    "    df['isbelongs_to_collectionNA'] = 0\n",
    "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
    "    \n",
    "    df['isTaglineNA'] = 0\n",
    "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
    "\n",
    "    df['isOriginalLanguageEng'] = 0 \n",
    "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
    "    \n",
    "    df['isTitleDifferent'] = 1\n",
    "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
    "\n",
    "    df['isMovieReleased'] = 1\n",
    "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
    "\n",
    "    # get collection id\n",
    "    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
    "    \n",
    "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
    "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
    "\n",
    "\n",
    "    df['title_word_count'] = df['title'].str.split().str.len()\n",
    "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
    "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
    "    \n",
    "    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n",
    "    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n",
    "    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n",
    "    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n",
    "    \n",
    "\n",
    "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
    "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
    "    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
    "    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n",
    "    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n",
    "    df['medianBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('median')\n",
    "\n",
    "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
    "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
    "        temp = df[col].str.get_dummies(sep=',')\n",
    "        df = pd.concat([df, temp], axis=1, sort=False)\n",
    "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
    "    \n",
    "    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
    "    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
    "    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n",
    "    ],axis=1)\n",
    "    \n",
    "    df.fillna(value=0.0, inplace = True) \n",
    "\n",
    "    return df\n",
    "train = pd.read_csv('/home/yash/introdatascience/project/data/train.csv')\n",
    "\n",
    "\n",
    "#power_six = train.id[train.budget > 1000][train.revenue < 100]\n",
    "\n",
    "#for k in power_six :\n",
    "#    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000\n",
    "#Clean Datapower_six \n",
    " \n",
    "train.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\n",
    "train.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \n",
    "train.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\n",
    "train.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\n",
    "train.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \n",
    "train.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\n",
    "train.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\n",
    "train.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\n",
    "train.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\n",
    "train.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\n",
    "train.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \n",
    "train.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\n",
    "train.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \n",
    "train.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \n",
    "train.loc[train['id'] == 1542,'budget'] = 1              # All at Once\n",
    "train.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\n",
    "train.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\n",
    "train.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\n",
    "train.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\n",
    "train.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\n",
    "train.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\n",
    "train.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\n",
    "train.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\n",
    "train.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\n",
    "train.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\n",
    "train.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\n",
    "train.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\n",
    "train.loc[train['id'] == 335,'budget'] = 2 \n",
    "train.loc[train['id'] == 348,'budget'] = 12\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
    "train.loc[train['id'] == 513,'budget'] = 1100000\n",
    "train.loc[train['id'] == 640,'budget'] = 6 \n",
    "train.loc[train['id'] == 696,'budget'] = 1\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
    "train.loc[train['id'] == 850,'budget'] = 1500000\n",
    "train.loc[train['id'] == 1199,'budget'] = 5 \n",
    "train.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\n",
    "train.loc[train['id'] == 1347,'budget'] = 1\n",
    "train.loc[train['id'] == 1755,'budget'] = 2\n",
    "train.loc[train['id'] == 1801,'budget'] = 5\n",
    "train.loc[train['id'] == 1918,'budget'] = 592 \n",
    "train.loc[train['id'] == 2033,'budget'] = 4\n",
    "train.loc[train['id'] == 2118,'budget'] = 344 \n",
    "train.loc[train['id'] == 2252,'budget'] = 130\n",
    "train.loc[train['id'] == 2256,'budget'] = 1 \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test = pd.read_csv('/home/yash/introdatascience/project/data/test.csv')\n",
    "\n",
    "#Clean Data\n",
    "test.loc[test['id'] == 6733,'budget'] = 5000000\n",
    "test.loc[test['id'] == 3889,'budget'] = 15000000\n",
    "test.loc[test['id'] == 6683,'budget'] = 50000000\n",
    "test.loc[test['id'] == 5704,'budget'] = 4300000\n",
    "test.loc[test['id'] == 6109,'budget'] = 281756\n",
    "test.loc[test['id'] == 7242,'budget'] = 10000000\n",
    "test.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\n",
    "test.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\n",
    "test.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n",
    "test.loc[test['id'] == 3033,'budget'] = 250 \n",
    "test.loc[test['id'] == 3051,'budget'] = 50\n",
    "test.loc[test['id'] == 3084,'budget'] = 337\n",
    "test.loc[test['id'] == 3224,'budget'] = 4  \n",
    "test.loc[test['id'] == 3594,'budget'] = 25  \n",
    "test.loc[test['id'] == 3619,'budget'] = 500  \n",
    "test.loc[test['id'] == 3831,'budget'] = 3  \n",
    "test.loc[test['id'] == 3935,'budget'] = 500  \n",
    "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
    "test.loc[test['id'] == 4424,'budget'] = 3  \n",
    "test.loc[test['id'] == 4460,'budget'] = 8  \n",
    "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
    "test.loc[test['id'] == 4624,'budget'] = 30 \n",
    "test.loc[test['id'] == 4645,'budget'] = 500 \n",
    "test.loc[test['id'] == 4709,'budget'] = 450 \n",
    "test.loc[test['id'] == 4839,'budget'] = 7\n",
    "test.loc[test['id'] == 3125,'budget'] = 25 \n",
    "test.loc[test['id'] == 3142,'budget'] = 1\n",
    "test.loc[test['id'] == 3201,'budget'] = 450\n",
    "test.loc[test['id'] == 3222,'budget'] = 6\n",
    "test.loc[test['id'] == 3545,'budget'] = 38\n",
    "test.loc[test['id'] == 3670,'budget'] = 18\n",
    "test.loc[test['id'] == 3792,'budget'] = 19\n",
    "test.loc[test['id'] == 3881,'budget'] = 7\n",
    "test.loc[test['id'] == 3969,'budget'] = 400\n",
    "test.loc[test['id'] == 4196,'budget'] = 6\n",
    "test.loc[test['id'] == 4221,'budget'] = 11\n",
    "test.loc[test['id'] == 4222,'budget'] = 500\n",
    "test.loc[test['id'] == 4285,'budget'] = 11\n",
    "test.loc[test['id'] == 4319,'budget'] = 1\n",
    "test.loc[test['id'] == 4639,'budget'] = 10\n",
    "test.loc[test['id'] == 4719,'budget'] = 45\n",
    "test.loc[test['id'] == 4822,'budget'] = 22\n",
    "test.loc[test['id'] == 4829,'budget'] = 20\n",
    "test.loc[test['id'] == 4969,'budget'] = 20\n",
    "test.loc[test['id'] == 5021,'budget'] = 40 \n",
    "test.loc[test['id'] == 5035,'budget'] = 1 \n",
    "test.loc[test['id'] == 5063,'budget'] = 14 \n",
    "test.loc[test['id'] == 5119,'budget'] = 2 \n",
    "test.loc[test['id'] == 5214,'budget'] = 30 \n",
    "test.loc[test['id'] == 5221,'budget'] = 50 \n",
    "test.loc[test['id'] == 4903,'budget'] = 15\n",
    "test.loc[test['id'] == 4983,'budget'] = 3\n",
    "test.loc[test['id'] == 5102,'budget'] = 28\n",
    "test.loc[test['id'] == 5217,'budget'] = 75\n",
    "test.loc[test['id'] == 5224,'budget'] = 3 \n",
    "test.loc[test['id'] == 5469,'budget'] = 20 \n",
    "test.loc[test['id'] == 5840,'budget'] = 1 \n",
    "test.loc[test['id'] == 5960,'budget'] = 30\n",
    "test.loc[test['id'] == 6506,'budget'] = 11 \n",
    "test.loc[test['id'] == 6553,'budget'] = 280\n",
    "test.loc[test['id'] == 6561,'budget'] = 7\n",
    "test.loc[test['id'] == 6582,'budget'] = 218\n",
    "test.loc[test['id'] == 6638,'budget'] = 5\n",
    "test.loc[test['id'] == 6749,'budget'] = 8 \n",
    "test.loc[test['id'] == 6759,'budget'] = 50 \n",
    "test.loc[test['id'] == 6856,'budget'] = 10\n",
    "test.loc[test['id'] == 6858,'budget'] =  100\n",
    "test.loc[test['id'] == 6876,'budget'] =  250\n",
    "test.loc[test['id'] == 6972,'budget'] = 1\n",
    "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
    "test.loc[test['id'] == 7150,'budget'] = 118\n",
    "test.loc[test['id'] == 6506,'budget'] = 118\n",
    "test.loc[test['id'] == 7225,'budget'] = 6\n",
    "test.loc[test['id'] == 7231,'budget'] = 85\n",
    "test.loc[test['id'] == 5222,'budget'] = 5\n",
    "test.loc[test['id'] == 5322,'budget'] = 90\n",
    "test.loc[test['id'] == 5350,'budget'] = 70\n",
    "test.loc[test['id'] == 5378,'budget'] = 10\n",
    "test.loc[test['id'] == 5545,'budget'] = 80\n",
    "test.loc[test['id'] == 5810,'budget'] = 8\n",
    "test.loc[test['id'] == 5926,'budget'] = 300\n",
    "test.loc[test['id'] == 5927,'budget'] = 4\n",
    "test.loc[test['id'] == 5986,'budget'] = 1\n",
    "test.loc[test['id'] == 6053,'budget'] = 20\n",
    "test.loc[test['id'] == 6104,'budget'] = 1\n",
    "test.loc[test['id'] == 6130,'budget'] = 30\n",
    "test.loc[test['id'] == 6301,'budget'] = 150\n",
    "test.loc[test['id'] == 6276,'budget'] = 100\n",
    "test.loc[test['id'] == 6473,'budget'] = 100\n",
    "test.loc[test['id'] == 6842,'budget'] = 30\n",
    "\n",
    "\n",
    "test['revenue'] = np.nan\n",
    "\n",
    "# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n",
    "train = pd.merge(train, pd.read_csv('/home/yash/introdatascience/project/data/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
    "test = pd.merge(test, pd.read_csv('/home/yash/introdatascience/project/data/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
    "# print(\"testrevenur\", test['id'])\n",
    "additionalTrainData = pd.read_csv('/home/yash/introdatascience/project/data/additionalTrainData.csv')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '/')\n",
    "train = pd.concat([train, additionalTrainData])\n",
    "\n",
    "#train = pd.merge(train, additionalTrainData, how='left', on=['imdb_id'],axis=1)\n",
    "# print(train.columns)\n",
    "# print(train.shape)\n",
    "train['revenue'] = np.log1p(train['revenue'])\n",
    "y = train['revenue'].values\n",
    "\n",
    "y_testing_revenue = np.log1p(test['revenue']).values\n",
    "\n",
    "json_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n",
    "\n",
    "def get_dictionary(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d\n",
    "\n",
    "for col in tqdm(json_cols + ['belongs_to_collection']) :\n",
    "    train[col] = train[col].apply(lambda x : get_dictionary(x))\n",
    "    test[col] = test[col].apply(lambda x : get_dictionary(x))\n",
    "    \n",
    "def get_json_dict(df) :\n",
    "    global json_cols\n",
    "    result = dict()\n",
    "    for e_col in json_cols :\n",
    "        d = dict()\n",
    "        rows = df[e_col].values\n",
    "        for row in rows :\n",
    "            if row is None : continue\n",
    "            for i in row :\n",
    "                if i['name'] not in d :\n",
    "                    d[i['name']] = 0\n",
    "                d[i['name']] += 1\n",
    "        result[e_col] = d\n",
    "    return result\n",
    "\n",
    "train_dict = get_json_dict(train)\n",
    "test_dict = get_json_dict(test)\n",
    "\n",
    "# remove cateogry with bias and low frequency\n",
    "for col in json_cols :\n",
    "    \n",
    "    remove = []\n",
    "    train_id = set(list(train_dict[col].keys()))\n",
    "    test_id = set(list(test_dict[col].keys()))   \n",
    "    \n",
    "    remove += list(train_id - test_id) + list(test_id - train_id)\n",
    "    for i in train_id.union(test_id) - set(remove) :\n",
    "        if train_dict[col][i] < 10 or i == '' :\n",
    "            remove += [i]\n",
    "            \n",
    "    for i in remove :\n",
    "        if i in train_dict[col] :\n",
    "            del train_dict[col][i]\n",
    "        if i in test_dict[col] :\n",
    "            del test_dict[col][i]\n",
    "            \n",
    "all_data = prepare(pd.concat([train, test]).reset_index(drop = True))\n",
    "train = all_data.loc[:train.shape[0] - 1,:]\n",
    "test = all_data.loc[train.shape[0]:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5001, 204)\n",
      "(4398, 204)\n",
      "(5001,)\n",
      "(4398,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(y.shape)\n",
    "print(y_testing_revenue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"budget\", \"popularity\",\"popularity2\",\"totalVotes\",\"rating\",\"release_month\",\"release_day\",\"release_dayofweek\",\"release_quarter\"]\n",
    "# cat_cols = [\"original_language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train[num_cols]\n",
    "test = test[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popularity2</th>\n",
       "      <th>rating</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_dayofweek</th>\n",
       "      <th>release_quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>UK Film Council</th>\n",
       "      <th>United Artists</th>\n",
       "      <th>Universal Pictures</th>\n",
       "      <th>Village Roadshow Pictures</th>\n",
       "      <th>Walt Disney Pictures</th>\n",
       "      <th>Warner Bros.</th>\n",
       "      <th>Wild Bunch</th>\n",
       "      <th>Wildwood Enterprises</th>\n",
       "      <th>Working Title Films</th>\n",
       "      <th>production_companies_etc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.454568</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>10.400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.504390</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>15.229</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.009433</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>26.082</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7314.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.997833</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>5.531</td>\n",
       "      <td>7.5</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>13.815512</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.829626</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>10.020070</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1915</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9.740321</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1914</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>21.487563</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  popularity  popularity2  rating  totalVotes  release_month  \\\n",
       "0     16.454568    6.575393       10.400     5.0       482.0              2   \n",
       "1     17.504390    8.248895       15.229     6.4      1528.0              8   \n",
       "2     15.009433   64.299990       26.082     8.4      7314.0             10   \n",
       "3     13.997833    3.174936        5.531     7.5       115.0              3   \n",
       "4      0.000000    1.148070        0.000     0.0         0.0              2   \n",
       "...         ...         ...          ...     ...         ...            ...   \n",
       "4996  13.815512    0.680000        0.000     5.0         1.0             16   \n",
       "4997   9.829626    0.600000        0.000     0.0         0.0              7   \n",
       "4998  10.020070    0.600000        0.000     0.0         0.0             15   \n",
       "4999   9.740321    0.600000        0.000     0.0         0.0             15   \n",
       "5000  21.487563    0.600000        0.000     0.0         0.0             14   \n",
       "\n",
       "      release_day  release_year  release_dayofweek  release_quarter  ...  \\\n",
       "0              20          2015                4.0              1.0  ...   \n",
       "1               6          2004                4.0              3.0  ...   \n",
       "2              10          2014                4.0              4.0  ...   \n",
       "3               9          2012                4.0              1.0  ...   \n",
       "4               5          2009                3.0              1.0  ...   \n",
       "...           ...           ...                ...              ...  ...   \n",
       "4996           10          1916                0.0              4.0  ...   \n",
       "4997            5          1916                2.0              3.0  ...   \n",
       "4998           12          1915                2.0              4.0  ...   \n",
       "4999           11          1914                6.0              4.0  ...   \n",
       "5000            4          1914                1.0              2.0  ...   \n",
       "\n",
       "      UK Film Council  United Artists  Universal Pictures  \\\n",
       "0                   0               1                   0   \n",
       "1                   0               0                   0   \n",
       "2                   0               0                   0   \n",
       "3                   0               0                   0   \n",
       "4                   0               0                   0   \n",
       "...               ...             ...                 ...   \n",
       "4996                0               0                   0   \n",
       "4997                0               0                   0   \n",
       "4998                0               0                   0   \n",
       "4999                0               0                   0   \n",
       "5000                0               0                   0   \n",
       "\n",
       "      Village Roadshow Pictures  Walt Disney Pictures  Warner Bros.  \\\n",
       "0                             0                     0             0   \n",
       "1                             0                     1             0   \n",
       "2                             0                     0             0   \n",
       "3                             0                     0             0   \n",
       "4                             0                     0             0   \n",
       "...                         ...                   ...           ...   \n",
       "4996                          0                     0             0   \n",
       "4997                          0                     0             0   \n",
       "4998                          0                     0             0   \n",
       "4999                          0                     0             0   \n",
       "5000                          0                     0             0   \n",
       "\n",
       "      Wild Bunch  Wildwood Enterprises  Working Title Films  \\\n",
       "0              0                     0                    0   \n",
       "1              0                     0                    0   \n",
       "2              0                     0                    0   \n",
       "3              0                     0                    0   \n",
       "4              0                     0                    0   \n",
       "...          ...                   ...                  ...   \n",
       "4996           0                     0                    0   \n",
       "4997           0                     0                    0   \n",
       "4998           0                     0                    0   \n",
       "4999           0                     0                    0   \n",
       "5000           0                     0                    0   \n",
       "\n",
       "      production_companies_etc  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            1  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "4996                         0  \n",
       "4997                         0  \n",
       "4998                         0  \n",
       "4999                         0  \n",
       "5000                         0  \n",
       "\n",
       "[5001 rows x 204 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random_seed = 2019\n",
    "k = 10\n",
    "fold = list(KFold(k, shuffle = True, random_state = random_seed).split(train))\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popularity2</th>\n",
       "      <th>rating</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_dayofweek</th>\n",
       "      <th>release_quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>UK Film Council</th>\n",
       "      <th>United Artists</th>\n",
       "      <th>Universal Pictures</th>\n",
       "      <th>Village Roadshow Pictures</th>\n",
       "      <th>Walt Disney Pictures</th>\n",
       "      <th>Warner Bros.</th>\n",
       "      <th>Wild Bunch</th>\n",
       "      <th>Wildwood Enterprises</th>\n",
       "      <th>Working Title Films</th>\n",
       "      <th>production_companies_etc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.454568</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>10.400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.504390</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>15.229</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.009433</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>26.082</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7314.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.997833</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>5.531</td>\n",
       "      <td>7.5</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>13.815512</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.829626</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>10.020070</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1915</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9.740321</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1914</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>21.487563</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  popularity  popularity2  rating  totalVotes  release_month  \\\n",
       "0     16.454568    6.575393       10.400     5.0       482.0              2   \n",
       "1     17.504390    8.248895       15.229     6.4      1528.0              8   \n",
       "2     15.009433   64.299990       26.082     8.4      7314.0             10   \n",
       "3     13.997833    3.174936        5.531     7.5       115.0              3   \n",
       "4      0.000000    1.148070        0.000     0.0         0.0              2   \n",
       "...         ...         ...          ...     ...         ...            ...   \n",
       "4996  13.815512    0.680000        0.000     5.0         1.0             16   \n",
       "4997   9.829626    0.600000        0.000     0.0         0.0              7   \n",
       "4998  10.020070    0.600000        0.000     0.0         0.0             15   \n",
       "4999   9.740321    0.600000        0.000     0.0         0.0             15   \n",
       "5000  21.487563    0.600000        0.000     0.0         0.0             14   \n",
       "\n",
       "      release_day  release_year  release_dayofweek  release_quarter  ...  \\\n",
       "0              20          2015                4.0              1.0  ...   \n",
       "1               6          2004                4.0              3.0  ...   \n",
       "2              10          2014                4.0              4.0  ...   \n",
       "3               9          2012                4.0              1.0  ...   \n",
       "4               5          2009                3.0              1.0  ...   \n",
       "...           ...           ...                ...              ...  ...   \n",
       "4996           10          1916                0.0              4.0  ...   \n",
       "4997            5          1916                2.0              3.0  ...   \n",
       "4998           12          1915                2.0              4.0  ...   \n",
       "4999           11          1914                6.0              4.0  ...   \n",
       "5000            4          1914                1.0              2.0  ...   \n",
       "\n",
       "      UK Film Council  United Artists  Universal Pictures  \\\n",
       "0                   0               1                   0   \n",
       "1                   0               0                   0   \n",
       "2                   0               0                   0   \n",
       "3                   0               0                   0   \n",
       "4                   0               0                   0   \n",
       "...               ...             ...                 ...   \n",
       "4996                0               0                   0   \n",
       "4997                0               0                   0   \n",
       "4998                0               0                   0   \n",
       "4999                0               0                   0   \n",
       "5000                0               0                   0   \n",
       "\n",
       "      Village Roadshow Pictures  Walt Disney Pictures  Warner Bros.  \\\n",
       "0                             0                     0             0   \n",
       "1                             0                     1             0   \n",
       "2                             0                     0             0   \n",
       "3                             0                     0             0   \n",
       "4                             0                     0             0   \n",
       "...                         ...                   ...           ...   \n",
       "4996                          0                     0             0   \n",
       "4997                          0                     0             0   \n",
       "4998                          0                     0             0   \n",
       "4999                          0                     0             0   \n",
       "5000                          0                     0             0   \n",
       "\n",
       "      Wild Bunch  Wildwood Enterprises  Working Title Films  \\\n",
       "0              0                     0                    0   \n",
       "1              0                     0                    0   \n",
       "2              0                     0                    0   \n",
       "3              0                     0                    0   \n",
       "4              0                     0                    0   \n",
       "...          ...                   ...                  ...   \n",
       "4996           0                     0                    0   \n",
       "4997           0                     0                    0   \n",
       "4998           0                     0                    0   \n",
       "4999           0                     0                    0   \n",
       "5000           0                     0                    0   \n",
       "\n",
       "      production_companies_etc  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            1  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "4996                         0  \n",
       "4997                         0  \n",
       "4998                         0  \n",
       "4999                         0  \n",
       "5000                         0  \n",
       "\n",
       "[5001 rows x 204 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    params = {'objective': 'reg:linear', \n",
    "              'eta': 0.01, \n",
    "              'max_depth': 6, \n",
    "              'subsample': 0.6, \n",
    "              'colsample_bytree': 0.7,  \n",
    "              '1': 'rmse', \n",
    "              'seed': random_seed, \n",
    "              'silent': True,\n",
    "    }\n",
    "    \n",
    "    record = dict()\n",
    "    model = xgb.train(params\n",
    "                      , xgb.DMatrix(trn_x, trn_y)\n",
    "                      , 100000\n",
    "                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n",
    "                      , verbose_eval=verbose\n",
    "                      , early_stopping_rounds=500\n",
    "                      , callbacks = [xgb.callback.record_evaluation(record)])\n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=100000,\n",
    "                                 learning_rate=0.004,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.8,\n",
    "                                 random_seed = random_seed,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None,\n",
    "                                 early_stopping_rounds=200\n",
    "                                )\n",
    "    model.fit(trn_x, trn_y,\n",
    "                 eval_set=(val_x, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=False)\n",
    "    \n",
    "    val_pred = model.predict(val_x)\n",
    "    test_pred = model.predict(test)\n",
    "#     print(\"catmodel\",model.get_best_score())\n",
    "    return {'val':val_pred, \n",
    "            'test':test_pred, \n",
    "            'error':model.get_best_score()['validation']['RMSE']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "fold_val_pred.append(result['val']*0.4)\n",
    "fold_test_pred.append(result['test']*0.4)\n",
    "fold_err.append(result['error'])\n",
    "print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.934574185203687}, 'validation': {'RMSE': 2.4085139491654703}}\n",
      "cat model. 2.40851 (0m)\n",
      "2 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.8961070204590718}, 'validation': {'RMSE': 1.8209974943215514}}\n",
      "cat model. 1.82100 (0m)\n",
      "3 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.5476202126888228}, 'validation': {'RMSE': 2.2338004382820915}}\n",
      "cat model. 2.23380 (1m)\n",
      "4 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.8448837858545044}, 'validation': {'RMSE': 1.8401289407239154}}\n",
      "cat model. 1.84013 (1m)\n",
      "5 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.7180681387295977}, 'validation': {'RMSE': 2.26549758770085}}\n",
      "cat model. 2.26550 (1m)\n",
      "6 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.9743231005258906}, 'validation': {'RMSE': 2.2608075148579365}}\n",
      "cat model. 2.26081 (0m)\n",
      "7 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.5686601052712263}, 'validation': {'RMSE': 2.116610901906148}}\n",
      "cat model. 2.11661 (1m)\n",
      "8 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.903832960997824}, 'validation': {'RMSE': 2.4110507242722923}}\n",
      "cat model. 2.41105 (0m)\n",
      "9 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.695516373801263}, 'validation': {'RMSE': 2.1995980594221587}}\n",
      "cat model. 2.19960 (1m)\n",
      "10 fold.    RMSE\n",
      "catmodel {'learn': {'RMSE': 1.8542570040804316}, 'validation': {'RMSE': 2.175177607845905}}\n",
      "cat model. 2.17518 (0m)\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "validationy = []\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    #\"\"\" xgboost\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val']*0.4)\n",
    "    fold_test_pred.append(result['test']*0.4)\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression',\n",
    "         'num_leaves' : 30,\n",
    "         'min_data_in_leaf' : 20,\n",
    "         'max_depth' : 9,\n",
    "         'learning_rate': 0.004,\n",
    "         #'min_child_samples':100,\n",
    "         'feature_fraction':0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         'lambda_l1': 0.2,\n",
    "         \"bagging_seed\": random_seed,\n",
    "         \"metric\": 'rmse',\n",
    "         #'subsample':.8, \n",
    "          #'colsample_bytree':.9,\n",
    "         \"random_state\" : random_seed,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 100000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 500\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.42787 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.934574185203687}, 'validation': {'RMSE': 2.4085139491654703}}\n",
      "cat model. 2.40851 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.41819\n",
      "blend err. 10.78210\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 1.81059 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.8961070204590718}, 'validation': {'RMSE': 1.8209974943215514}}\n",
      "cat model. 1.82100 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.81579\n",
      "blend err. 10.91164\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.26332 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.5476202126888228}, 'validation': {'RMSE': 2.2338004382820915}}\n",
      "cat model. 2.23380 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.24856\n",
      "blend err. 10.73812\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 1.86640 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.8448837858545044}, 'validation': {'RMSE': 1.8401289407239154}}\n",
      "cat model. 1.84013 (0m)\n",
      "---------------------------\n",
      "avg   err. 1.85326\n",
      "blend err. 10.82757\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.20771 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.7180681387295977}, 'validation': {'RMSE': 2.26549758770085}}\n",
      "cat model. 2.26550 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.23661\n",
      "blend err. 10.75313\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.29014 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.9743231005258906}, 'validation': {'RMSE': 2.2608075148579365}}\n",
      "cat model. 2.26081 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.27548\n",
      "blend err. 10.93730\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.10166 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.5686601052712263}, 'validation': {'RMSE': 2.116610901906148}}\n",
      "cat model. 2.11661 (2m)\n",
      "---------------------------\n",
      "avg   err. 2.10914\n",
      "blend err. 10.97774\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.37742 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.903832960997824}, 'validation': {'RMSE': 2.4110507242722923}}\n",
      "cat model. 2.41105 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.39423\n",
      "blend err. 10.71824\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.28308 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.695516373801263}, 'validation': {'RMSE': 2.1995980594221587}}\n",
      "cat model. 2.19960 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.24134\n",
      "blend err. 10.73016\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.21398 (0m)\n",
      "catmodel {'learn': {'RMSE': 1.8542570040804316}, 'validation': {'RMSE': 2.175177607845905}}\n",
      "cat model. 2.17518 (0m)\n",
      "---------------------------\n",
      "avg   err. 2.19458\n",
      "blend err. 10.83264\n",
      "\n",
      "fianl avg   err. 2.178717960924916\n",
      "fianl blend err. 10.821217624924426\n"
     ]
    }
   ],
   "source": [
    "#ensemble model\\\n",
    "\n",
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    #\"\"\" xgboost\n",
    "    start = datetime.now()\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val']*0.2)\n",
    "    fold_test_pred.append(result['test']*0.2)\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    #\"\"\"\n",
    "    \n",
    "#     #\"\"\" lightgbm\n",
    "#     start = datetime.now()\n",
    "#     result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "#     fold_val_pred.append(result['val']*0.4)\n",
    "#     fold_test_pred.append(result['test']*0.4)\n",
    "#     fold_err.append(result['error'])\n",
    "#     print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "#     #\"\"\"\n",
    "    \n",
    "    #\"\"\" catboost model\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val']*0.4)\n",
    "    fold_test_pred.append(result['test']*0.4)\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    #\"\"\"\n",
    "    \n",
    "    # mix result of multiple models\n",
    "    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    #print(fold_test_pred)\n",
    "    #print(fold_test_pred.shape)\n",
    "    #print(fold_test_pred.columns)\n",
    "    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / k\n",
    "    final_err += (sum(fold_err) / len(fold_err)) / k\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "errensemble = np.array([2.41819,1.81579,2.24856, 1.85326, 2.23661,2.27548,2.10914, 2.39423,2.24134,2.19458])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "errxgboost = np.array([2.42787,1.81059, 2.26332,1.86640, 2.20771,2.29014,2.10166,2.37742,2.21398 ])\n",
    "errcatboost = np.array([2.4085139491654703, 1.8209974943215514, 2.2338004382820915,1.8401289407239154,2.26549758770085,2.2608075148579365, 2.116610901906148,  2.4110507242722923,2.1995980594221587,2.175177607845905 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(errxgboost,'r',label='xgboost')\n",
    "plt.plot(errcatboost,'b',label='catboost')\n",
    "plt.plot(errensemble,'g',label='ensemble')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-278-180d093f7ca6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-278-180d093f7ca6>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    plt.plot(np.exp(errcatboost,'b',label='catboost')\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.42787 (0m)\n",
      "2 fold.    RMSE\n",
      "xgb model. 1.81059 (0m)\n",
      "3 fold.    RMSE\n",
      "xgb model. 2.26332 (0m)\n",
      "4 fold.    RMSE\n",
      "xgb model. 1.86640 (0m)\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.20771 (0m)\n",
      "6 fold.    RMSE\n",
      "xgb model. 2.29014 (0m)\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.10166 (0m)\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.37742 (0m)\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.28308 (0m)\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.21398 (0m)\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "validationy = []\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    #\"\"\" xgboost\n",
    "    start = datetime.now()\n",
    "#     print(list(test))\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "   \n",
    "    fold_val_pred.append(result['val']*0.2)\n",
    "    validationy.append(val_y)\n",
    "    fold_test_pred.append(result['test']*0.2)\n",
    "#     rmse = np.sqrt(mean_squared_error(test, result['test']*0.2))\n",
    "#     print(\"testshape\", test.shape)\n",
    "#     print(\"RMSE_test: %f\" % (rmse))\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAI/CAYAAAABYR7qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3iVVaK28edNLwRCCgESklCSAErvYKfZQbCMbWwUnbGLjufMzDfnnJlzpojK2LsiltFRHLt0EFFqEFAgBQiQUJIQEtLL3uv7g4joIAZIsna5f9fltUkI5AExum/fvV7HGCMAAAAAAAD4ngDbAwAAAAAAANAyCD8AAAAAAAA+ivADAAAAAADgowg/AAAAAAAAPorwAwAAAAAA4KMIPwAAAAAAAD4qqDU/WVxcnElNTW3NTwkAAAAAAODT1q1bV2yMiT/W97Vq+ElNTdXatWtb81MCAAAAAAD4NMdxdv7U9/FSLwAAAAAAAB9F+AEAAAAAAPBRhB8AAAAAAAAfRfgBAAAAAADwUYQfAAAAAAAAH0X4AQAAAAAA8FGEHwAAAAAAAB9F+AEAAAAAAPBRhB8AAAAAAAAfRfgBAAAAAADwUYQfAAAAAAAAH0X4AQAAAAAA8FGEHwAAAAAAAB9F+AEAAAAAAPBRhB8AAAAAAAAfRfgBAAAAAADwUYQfAAAAAAAAH0X4AQAAAAAA8FGEHwAAAAAAAB9F+AEAAAAAAPBRhB8AAAAAAAAfRfgBAAAAAAB+xeU2MsbYntEqCD8AAAAAAMCvvLFqpyY8uUKlVXW2p7Q4wg8AAAAAAPAb1XUuPb44V6FBAWoXHmx7Tosj/AAAAAAAAL8xZ2WeCstrNWNchhzHsT2nxRF+AAAAAACAXyivqdfTS7fpzLQ4DesWa3tOqyD8AAAAAAAAv/DSF3k6WFWvGeMybE9pNYQfAAAAAADg80qr6vTC8u0a1ztB/bpE257Tagg/AAAAAADA5z2zbLsq6hp0nx9d7SMRfgAAAAAAgI8rLK/RK1/u0KX9OiujY5TtOa2K8AMAAAAAAHzaU0u2qd5ldM+YdNtTWh3hBwAAAAAA+KyC0mq9sWqXrhiUpNS4SNtzWh3hBwAAAAAA+KzHFuZIku4YnWZ5iR2EHwAAAAAA4JN2FFfqncx8XTMsWYnR4bbnWEH4AQAAAAAAPunRBdkKCQzQr8/tYXuKNYQfAAAAAADgc7buO6QPN+7RjaNSFR8VanuONYQfAAAAAADgcx6en602IUGaflY321OsIvwAAAAAAACfsmF3qRZs3q+pZ3VTdESI7TlWEX4AAAAAAIBPmTk/SzGRIbr5jK62p1hH+AEAAAAAAD5j1fYDWp5TrNvO7q42oUG251hH+AEAAAAAAD7BGKOZ87PUISpU149IsT3HIxB+AAAAAACAT1iWXaQ1eQd1x3k9FBYcaHuORyD8AAAAAAAAr2eM0cPzs5XUPlxXDUm2PcdjEH4AAAAAAIDXm/ftPm0qKNNdo9MUEkTu+A6/EwAAAAAAwKu53Iev9ukWH6nLBiTanuNRCD8AAAAAAMCrfbChQDmFFbp3bLqCAkkdR+N3AwAAAAAAeK16l1uPLshRr05tdeHpnWzP8TiEHwAAAAAA4LX+uTZfu0qqNGNcugICHNtzPA7hBwAAAAAAeKWaepceX5yjAcnROq9nB9tzPBLhBwAAAAAAeKXXV+3S3rIa3T8uQ47D1T7HQvgBAAAAAABep7K2QU8tydXI7rEa2SPO9hyPRfgBAAAAAABe55Uv83Sgsk4zxmfYnuLRCD8AAAAAAMCrlFXX69ll2zS6ZwcNTG5ve45HI/wAAAAAAACv8vzn23WopkH3jku3PcXjEX4AAAAAAIDXKK6o1Usrduiivp10Wud2tud4PMIPAAAAAADwGk8v3aaaepfuGcPVPk1B+AEAAAAAAF5hb1m15qzcqUkDk9SjQxvbc7wC4QcAAAAAAHiFxxfnyhiju0an2Z7iNQg/AAAAAADA4+06UKW31+zWL4Ykq0tMhO05XoPwAwAAAAAAPN6shdkKDHB0+3k9bE/xKkFN+SDHcfIklUtySWowxgx2HCdG0luSUiXlSbrSGHOwZWYCAAAAAAB/lbO/XO99XaCpZ3ZTQtsw23O8yolc8XOuMaa/MWZw49sPSlpkjEmTtKjxbQAAAAAAgGb1yIJsRYYE6dazu9ue4nVO5aVeEyTNbvz2bEkTT30OAAAAAADA974pKNOn3+zTzWd0VUxkiO05Xqep4cdImu84zjrHcaY1vi/BGLNXkhofO7TEQAAAAAAA4L9mzs9Su/BgTTmzq+0pXqlJZ/xIGmWM2eM4TgdJCxzH2drUT9AYiqZJUnJy8klMBAAAAAAA/mhtXomWZhXpN+f3VNuwYNtzvFKTrvgxxuxpfCyU9J6koZL2O47TSZIaHwt/4sc+Z4wZbIwZHB8f3zyrAQAAAACATzPG6KF5WYprE6obRqbYnuO1fjb8OI4T6ThO1HffljRO0jeSPpB0Q+OH3SDp/ZYaCQAAAAAA/MuK3ANataNEt5/bXREhTX3BEn6sKb9zCZLecxznu49/wxjzmeM4ayS97TjOLZJ2Sbqi5WYCAAAAAAB/YYzRQ/OzlBgdrquHcWzMqfjZ8GOM2S6p3zHef0DS6JYYBQAAAAAA/NfCLYXasLtUf53cR6FBgbbneLVTuZ07AAAAAABAs3K7jR6en6WucZGaPDDJ9hyvR/gBAAAAAAAe46NNe7V1X7nuHpOmoECyxanidxAAAAAAAHiEBpdbsxZkKyMhSpf07Wx7jk8g/AAAAAAAAI8wN7NA24srde+4dAUEOLbn+ATCDwAAAAAAsK62waW/L8pRv6R2Gtc7wfYcn0H4AQAAAAAA1v1j9W4VlFbrvnEZchyu9mkuhB8AAAAAAGBVdZ1LTyzJ1dCuMTozLc72HJ9C+AEAAAAAAFbN/ipPReW1un88V/s0N8IPAAAAAACw5lBNvZ5Ztk1np8drSGqM7Tk+h/ADAAAAAACseXH5DpVW1WvGuAzbU3wS4QcAAAAAAFhxsLJOL36xQ+ef1lF9ktrZnuOTCD8AAAAAAMCKZ5ZtU2Vdg+4dl257is8i/AAAAAAAgFZXeKhGs7/K08T+iUpPiLI9x2cRfgAAAAAAQKt7YkmuGlxGd49Jsz3FpxF+AAAAAABAq9pdUqU3V+/SFYO7KCU20vYcn0b4AQAAAAAAreqxRTlyHEd3ju5he4rPI/wAAAAAAIBWs62oQu9m5uu6YSnq1C7c9hyfR/gBAAAAAACt5tEF2QoLDtSvzu1ue4pfIPwAAAAAAIBWsXnPIX20ca9uGpWquDahtuf4BcIPAAAAAABoFY8syFJUWJCmncnVPq2F8AMAAAAAAFpc5q6DWrilUNPP6qZ2EcG25/gNwg8AAAAAAGhxD8/PUmxkiG4a1dX2FL9C+AEAAAAAAC3qy23FWpF7QLed012RoUG25/gVwg8AAAAAAGgxxhjNnJeljm3DdN3wFNtz/A7hBwAAAAAAtJglWYXK3FWqO0b3UFhwoO05fofwAwAAAAAAWoTbbTRzXraSYyJ05eAutuf4JcIPAAAAAABoEZ9+s0+b9x7S3WPSFBxIgrCB33UAAAAAANDsXG6jRxZkKa1DG03on2h7jt8i/AAAAAAAgGb3r/UF2lZUqXvHpiswwLE9x28RfgAAAAAAQLOqa3Br1qJsnZ7YVuef3tH2HL9G+AEAAAAAAM3q7bW7tbukWveNy5DjcLWPTYQfAAAAAADQbGrqXXp8cY4Gp7TXOenxtuf4PcIPAAAAAABoNq+t3Kn9h2o1YzxX+3gCwg8AAAAAAGgWFbUNemrpNp3RI07Du8XangMRfgAAAAAAQDN5+YsdKqms04zxGbanoBHhBwAAAAAAnLKyqno9t3y7xvRKUP8u0bbnoBHhBwAAAAAAnLJnP9+mitoG3Tcu3fYUHIXwAwAAAAAATklRea1eXpGni/t2Vq9ObW3PwVEIPwAAAAAA4JQ8tTRXdS637hmTZnsKfoTwAwAAAAAATtqe0mq9vnKXJg9MVLf4Nrbn4EcIPwAAAAAA4KQ9vjhHRkZ3juZqH09E+AEAAAAAACclr7hSb6/N1zVDk5XUPsL2HBwD4QcAAAAAAJyUWQuzFRzo6Nfn9bA9BT+B8AMAAAAAAE5Y1r5yvb9hj24YmaoOUWG25+AnEH4AAAAAAMAJe2RBltqEBOnWs7rbnoLjIPwAAAAAAIATsjG/VPO+3a9bzuyq9pEhtufgOAg/AAAAAADghMycn632EcG65YyutqfgZxB+AAAAAABAk63eUaLPs4t069ndFRUWbHsOfgbhBwAAAAAANIkxRjPnZSk+KlS/HJFqew6agPADAAAAAACa5POcYq3OK9Ed5/VQeEig7TloAsIPAAAAAAD4WcYYPTw/S4nR4frFkGTbc9BEhB8AAAAAAPCz5n27Xxvzy3TXmDSFBJETvAV/pwAAAAAAwHG53EaPLMhSt/hITRqQaHsOTgDhBwAAAAAAHNeHG/Yoe3+F7hmTrqBAUoI34e8WAAAAAAD4SfUutx5dmK1endrqoj6dbM/BCSL8AAAAAACAn/TOunztPFCl+8amKyDAsT0HJ4jwAwAAAAAAjqmm3qXHFuWof5doje7VwfYcnATCDwAAAAAAOKY3V+/S3rIa3T8+Q47D1T7eiPADAAAAAAD+TVVdg55ckqsR3WI1qkec7Tk4SYQfAAAAAADwb175Mk/FFXWaMT7D9hScAsIPAAAAAAD4gbLqej27bLvO69lBg1La256DU0D4AQAAAAAAP/Di8u0qq67XfePSbU/BKSL8AAAAAACAIw5U1OrFL3booj6ddFrndrbn4BQRfgAAAAAAwBHPLNum6nqX7hnL1T6+gPADAAAAAAAkSfsP1ejVr3bqsgFJ6tGhje05aAaEHwAAAAAAIEl6fHGOXG6ju0an2Z6CZkL4AQAAAAAA2l1SpX+s3q2rhnRRcmyE7TloJoQfAAAAAACgWQtzFBjg6I7zuNrHlxB+AAAAAADwc7mF5Xpvfb6uH56iju3CbM9BMyL8AAAAAADg5x5dkKPw4EDddk5321PQzAg/AAAAAAD4sW8KyvTxpr26+Yyuim0TansOmhnhBwAAAAAAP/bIgmy1DQvSlDO72Z6CFkD4AQAAAADAT63beVCLtxZq+tnd1S482PYctADCDwAAAAAAfmrmvCzFtQnRTaNSbU9BCyH8AAAAAADgh1bkFuur7Qf0q3N6KCIkyPYctBDCDwAAAAAAfsYYo4fmZalTuzBdMyzZ9hy0IMIPAAAAAAB+ZtGWQn29u1R3jk5TWHCg7TloQYQfAAAAAAD8iNttNHN+llJiI3T5oCTbc9DCCD8AAAAAAPiRjzft1dZ95bpnTLqCA8kCvo6/wwAAAAAA+IkGl1uPLshWekIbXdKvs+05aAWEHwAAAAAA/MTc9QXaXlype8dmKDDAsT0HrYDwAwAAAACAH6htcOnvC3PUN6mdxp+WYHsOWgnhBwAAAAAAP/DWmt0qKK3WfeMy5Dhc7eMvCD8AAAAAAPi46jqXHl+cq6GpMTorLc72HLQiwg8AAAAAAD7u1a/yVFReqxnjudrH3xB+AAAAAADwYeU19Xp62TadlR6voV1jbM9BK2ty+HEcJ9BxnPWO43zU+HaM4zgLHMfJaXxs33IzAQAAAADAyXjxix0qrarXjHHptqfAghO54ucuSVuOevtBSYuMMWmSFjW+DQAAAAAAPMTByjq9uHyHxp+WoL5J0bbnwIImhR/HcZIkXSTphaPePUHS7MZvz5Y0sXmnAQAAAACAU/Hs59tVUdeg+8Zl2J4CS5p6xc8sSQ9Ich/1vgRjzF5Janzs0MzbAAAAAADASSosr9ErX+7QhH6dlZ4QZXsOLPnZ8OM4zsWSCo0x607mEziOM81xnLWO46wtKio6mZ8CAAAAAACcoKeWbFO9y+juMZzt48+acsXPKEmXOo6TJ+kfks5zHOc1Sfsdx+kkSY2Phcf6wcaY54wxg40xg+Pj45tpNgAAAAAA+CkFpdV6Y9UuXTk4SalxkbbnwKKfDT/GmP8wxiQZY1Il/ULSYmPMdZI+kHRD44fdIOn9FlsJAAAAAACa7LGFOZKkO85Ls7wEtp3IXb1+7C+SxjqOkyNpbOPbAAAAAADAoh3FlXonM1/XDk9W5+hw23NgWdCJfLAxZqmkpY3fPiBpdPNPAgAAAAAAJ+vRBdkKCQzQr87pYXsKPMCpXPEDAAAAAAA8yNZ9h/Thxj26aVSq4qNCbc+BByD8AAAAAADgIx6en602IUGadlY321PgIQg/AAAAAAD4gK93l2rB5v2aelY3RUeE2J4DD0H4AQAAAADABzw8P0sxkSG6+YyutqfAgxB+AAAAAADwciu3H9DynGLddnZ3tQk9ofs4wccRfgAAAAAA8GLGGM2cl6WEtqG6fkSK7TnwMIQfAAAAAAC82NLsIq3deVC3n5emsOBA23PgYQg/AAAAAAB4KWOMHp6fpaT24bpqcBfbc+CBCD8AAAAAAHipz77Zp28KDunuMekKCeIpPv4dfyoAAAAAAPBCLrfRwwuy1T0+UpcNSLQ9Bx6K8AMAAAAAgBd6/+sC5RZW6N6xGQoMcGzPgYci/AAAAAAA4GXqXW7NWpij3p3a6oLTO9qeAw9G+AEAAAAAwMu8vXa3dpVUacb4dAVwtQ+Og/ADAAAAAIAXqal36fFFuRqYHK1zMzrYngMPR/gBAAAAAMCLvLZyp/YdqtGM8RlyHK72wfERfgAAAAAA8BKVtQ16euk2jeoRq5Hd42zPgRcg/AAAAAAA4CVeXrFDByrrNGNchu0p8BKEHwAAAAAAvEBZVb2e/Xy7xvTqoAHJ7W3PgZcg/AAAAAAA4AWeW75N5TUNuncsV/ug6Qg/AAAAAAB4uOKKWr28Ik8X9+2k3p3b2p4DL0L4AQAAAADAwz21ZJtq6l26Z2y67SnwMoQfAAAAAAA82N6yar22aqcmD0xS9/g2tufAyxB+AAAAAADwYI8vzpUxRneOTrM9BV6I8AMAAAAAgIfadaBKb6/ZrauHJqtLTITtOfBChB8AAAAAADzUrIXZCgp0dPu5PWxPgZci/AAAAAAA4IFy9pfrva8LdMOIVHVoG2Z7DrwU4QcAAAAAAA/0yIJsRYYE6dazu9ueAi9G+AEAAAAAwMN8U1CmT7/Zp1vO6Kr2kSG258CLEX4AAAAAAPAwM+dnKToiWFPO7Gp7Crwc4QcAAAAAAA+yNq9ES7OKdOvZ3RUVFmx7Drwc4QcAAAAAAA9hjNFD87IUHxWqG0ak2p4DH0D4AQAAAADAQ3yRW6xVO0p0+7k9FB4SaHsOfADhBwAAAAAAD2CM0cx5WUqMDtcvhnaxPQc+gvADAAAAAIAHWLB5vzbkl+nO0T0UGsTVPmgehB8AAAAAACxzu40eWZCtrnGRmjwwyfYc+BDCDwAAAAAAln24cY+27ivX3WPSFBTIU3U0H/40AQAAAABgUYPLrVkLc9SzY5Qu6dvZ9hz4GMIPAAAAAAAWvZuZrx3Flbp3bLoCAhzbc+BjCD8AAAAAAFhS2+DSY4ty1a9LtMb2TrA9Bz6I8AMAAAAAgCVvrtqlgtJqzRiXLsfhah80P8IPAAAAAAAWVNU16Ikl2zSsa4zO6BFnew58FOEHAAAAAAALZn+5U8UVtbp/fAZX+6DFEH4AAAAAAGhlh2rq9cyybTonI16DU2Nsz4EPI/wAAAAAANDKXli+Q2XV9ZoxLsP2FPg4wg8AAAAAAK2opLJOLy7frgtO76jTE9vZngMfR/gBAAAAAKAVPbNsm6rqXbp3bLrtKfADhB8AAAAAAFrJ/kM1mv1lni7rn6i0hCjbc+AHCD8AAAAAALSSJxbnyuU2unsMV/ugdRB+AAAAAABoBbtLqvSPNbt05ZAuSo6NsD0HfoLwAwAAAABAK/j7ohw5jqM7zuthewr8COEHAAAAAIAWlltYobmZ+bp+eIo6tQu3PQd+hPADAAAAAEALe3RhtsKCA3XbOd1tT4GfIfwAAAAAANCCNu85pI837tXNo7oqrk2o7TnwM4QfAAAAAABa0CMLstQ2LEhTz+pmewr8EOEHAAAAAIAWkrnroBZuKdT0s7urXXiw7TnwQ4QfAAAAAABayMPzsxTXJkQ3jky1PQV+ivADAAAAAEAL+HJbsVbkHtBt5/RQZGiQ7TnwU4QfAAAAAACamTFGM+dlqVO7MF07LNn2HPgxwg8AAAAAAM1sSVahMneV6o7z0hQWHGh7DvwY4QcAAAAAgGbkdhvNnJetlNgIXTE4yfYc+DnCDwAAAAAAzejTb/Zp895DuntMmoIDedoNu/gTCAAAAABAM3G5jR5ZkKW0Dm10ab9E23MAwg8AAAAAAM3lvfUF2lZUqfvGpSswwLE9ByD8AAAAAADQHOoa3Jq1MFunJ7bV+NM62p4DSCL8AAAAAADQLN5au1v5B6t137gMOQ5X+8AzEH4AAAAAADhFNfUuPbE4R4NT2uuc9Hjbc4AjCD8AAAAAAJyiOV/t1P5DtZoxnqt94FkIPwAAAAAAnIKK2gY9vWybzkyL0/BusbbnAD9A+AEAAAAA4BS89MUOlVTW6b5xGbanAP+G8AMAAAAAwEkqrarT859v19jeCerfJdr2HODfEH4AAAAAADhJz36+XRV1DbpvXLrtKcAxEX4AAAAAADgJheU1emVFni7p21k9O7a1PQc4JsIPAAAAAAAn4akl21TncuuesVztA89F+AEAAAAA4AQVlFbrjVW7dPnAJHWNi7Q9B/hJhB8AAAAAAE7Q44tyJEl3jkmzvAQ4viDbAwAAAAAA8FQut9HesmrtOlClvANV2nmgUnkHKrVwS6GuH56ixOhw2xOB4yL8AAAAAAD8Wr3LrfyD1dp5oFI7D1Qpr/Fx54FK7S6pVp3LfeRjQwID1CUmXBec3lF3juZqH3g+wg8AAAAAwOfV1Lu0q6TqSND5Pu5UqaC0Wi63OfKxESGBSo6JUFqHKI3pnaCUmEilxkYoJS5SHduGKTDAsfgrAU4M4QcAAAAA4BPKa+q180CVdpU0XrVTfPhxV0mV9pbV/OBj24YFKTUuUv26RGtC/85KjolQalykUmIjFN8mVI5D3IFvIPwAAAAAALyCMUalVfVHYk5e8fdX7+wqqVJxRd0PPj6uTahSYiM0onusUmMPR52U2MNX70RHhFj6VQCti/ADAAAAAPAYxhgVldceOUj5x2fuHKpp+MHHd24XpuTYCI3plaCUI3HncOBpE8pTXoB/CgAAAAAAreq7O2V9d8bOj8/cqa53HfnYwABHSe3DlRwTof5dEpUSG3Hk6p0uMREKCw60+CsBPB/hBwAAAADQ7L67U9bhs3YqtbPxYOW8A5XKP8adspJjI5QSE6GR3eOUGnf4ip2UmAgltg9XcGCAxV8J4N0IPwAAAACAk/LdnbLyihuv1in5/qVZe0pr/u1OWSmxkUrvEKWxvRN+cOYOd8oCWg7hBwAAAADwk767U9Z3QWfXUWfu7Dv073fK6hoXqf5d2mti/+8PUk7mTlmANYQfAAAAAPBjR98p61hx50Dlv98pKzU2QiN7fH+nrO8euVMW4Hl+Nvw4jhMm6XNJoY0f/44x5g+O48RIektSqqQ8SVcaYw623FQAAAAAwMk4+k5Zh4NO5Q+u4ik/xp2yUmIjNbZ3wpGrdlJiI5UcG8GdsgAv05R/YmslnWeMqXAcJ1jSF47jfCppkqRFxpi/OI7zoKQHJf2mBbcCAAAAAH7C0XfKOvr258e7U1ZKbKT6d4k+ctVOalyEktpzpyzAl/xs+DHGGEkVjW8GN/5lJE2QdE7j+2dLWirCDwAAAAC0mLoGtwpKv79TVt6BqsOHKx/rTllBAUqOiTj8sqyj7pSVGhuhztHcKQvwF026Rs9xnEBJ6yT1kPSkMWaV4zgJxpi9kmSM2es4TocW3AkAAAAAfqG67vCdsnYefeZOY9wpOFito26UdeROWRkJP7xTVmrjnbICuFMW4PeaFH6MMS5J/R3HiZb0nuM4pzf1EziOM03SNElKTk4+qZEAAAAA4Euq6hq0vajyqJdlff+SrB/fKatdeLBSYyM0oEt7Teyf+IMzd+LahHCnLADHdUKnchljSh3HWSrpfEn7Hcfp1Hi1TydJhT/xY56T9JwkDR482BzrYwAAAADAX2zYXaobX16tg1X1R9733Z2yRvWIU0psBHfKAtBsmnJXr3hJ9Y3RJ1zSGEl/lfSBpBsk/aXx8f2WHAoAAAAA3m7dzhLd+NIaRUcG608T+6hrHHfKAtCymvLVpZOk2Y3n/ARIetsY85HjOF9JettxnFsk7ZJ0RQvuBAAAAACvtnL7Ad38yholtA3TG1OHqVO7cNuTAPiBptzVa6OkAcd4/wFJo1tiFAAAAAD4ki9yijXl1TXq0j5Cr08Zpg5tw2xPAuAnuJ4QAAAAAFrQkq2Fmv7aOnWLi9TrU4Yptk2o7UkA/EiA7QEAAAAA4KvmfbtP0+asVUZClN6cOpzoA6DVccUPAAAAALSAjzbu0V3/+Fp9k9rplZuGql14sO1JAPwQ4QcAAAAAmtl76/N139sbNDglRi/dNIS7dgGwhq8+AAAAANCM3lqzSw/O3aQR3WL1wg2DFRHC0y4A9vAVCAAAAACayZyv8vT797/V2enxevb6QQoLDrQ9CYCfI/wAAAAAQDN4Yfl2/enjLRrTK0FPXjtAoUFEHwD2EX4AAAAA4BQ9tTRXf/ssSxf26ahZVw1QSBA3UAbgGQg/AAAAAHCSjDH6+6IczVqYown9O+vhK/opKJDoA8BzEH4AAAAA4CQYY/TQvCw9tXSbLh+UpL9O7qvAAMf2LAD4AcIPAAAAAJwgY4z+9PEWvfjFDl0zLFl/mnC6Aog+ADwQ4QcAAAAAToDbbfSHD77VnJU7ddOoVP2/i3vLcYg+ADwT4eckGGP4wg4AAAD4IZfb6LfvbdI/1uzW9LO76cHze/LcAIBH49SxE1ReU6+JT32pz77ZZ3sKAAAAgFbU4HLr/n9u0D/W7Nad5/Ug+gDwCoSfE1Rd75Ik3fraOj08P0tut7G8CAAAAEBLq3e5dcf30yYAACAASURBVNdbX2vu+gLNGJeue8dlEH0AeAXCzwnqEBWmt6YN15WDk/T44lzdMnuNyqrrbc8CAAAA0EJqG1z69euZ+njjXv32wl66/bw025MAoMkIPychLDhQf53cV3+ccJqW5xRr4pMrlLO/3PYsAAAAAM2spt6lW+es0/zN+/Xfl56mqWd1sz0JAE4I4eckOY6j60ek6s1pw1Ve06CJT67QvG859wcAAADwFdV1Lk2ZvVZLs4v0f5f10Q0jU21PAoATRvg5RUNSY/ThHaPUIyFK0+es0yOc+wMAAAB4vcraBt348mp9ua1YD13eT9cMS7Y9CQBOCuGnGXRqF663pg3XFYOS9NjiXE15dS3n/gAAAABe6lBNvX750mqt3XlQs34xQJcPSrI9CQBOGuGnmYQFB+pvlx8+9+fz7CJNfHKFcgs59wcAAADwJmVV9br+hVXamF+qJ68ZoEv7dbY9CQBOCeGnGX137s8bU4ervKZeE5/8knN/AAAAAC9RUlmnq59fqS17y/XMdYN0/umdbE8CgFNG+GkBQ7vG6IPbz1D3+EjO/QEAAAC8QFF5rX7x3FfaVlShF24YrNG9EmxPAoBmQfhpIZ2jw/XW9BG6vPHcn6mvrtWhGs79AQAAADzNvrIaXfXcV9pdUq2Xbxqis9LjbU8CgGZD+GlBYcGBeujyvvqfCadpWXaRJj7BuT8AAACAJykordZVz32lwkO1evWWoRrZPc72JABoVoSfFuY4jn45IlWvTxmmQ43n/szn3B8AAADAul0HqnTlM1+ppLJOc24ZqiGpMbYnAUCzI/y0kmHdYvXB7WeoW3ykps1Zp0cWZHPuDwAAAGDJ9qIKXfnsV6qsa9CbU4drQHJ725MAoEUQflpR5+hwvf3duT+LcjRtDuf+AAAAAK0tZ3+5rnx2pepdbv1j2nCdntjO9iQAaDGEn1b23bk//33paVqaVaSJT65QbmGF7VkAAACAX9i855Cuem6lAhzprenD1bNjW9uTAKBFEX4scBxHN4w8fO5PWVW9Jj65Qgs277c9CwAAAPBpG/NLdfXzKxUaFKC3po9Qjw5RticBQIsj/Fg0rFusPrzj8Lk/U19dq0c59wcAAABoEZm7Dura51cpKixIb08foa5xkbYnAUCrIPxY9t25P5MHJunvi3I0bc46lXPuDwAAANBsVu8o0fUvrFJsmxC9PX2EusRE2J4EAK2G8OMBwoIDNfOKvvqvS3prSVahJnDuDwAAANAsVuQW64aXVqtjuzC9NX2EOkeH254EAK2K8OMhHMfRjaO6cu4PAAAA0EyWZhXq5lfWKCU2Qm9NH6GEtmG2JwFAqyP8eJjh3WL1wR1nqGvc4XN/Zi3k3B8AAADgRC3YvF/TXl2nHh3a6M2pwxXXJtT2JACwgvDjgRKjw/XPW0do0sBEzVrIuT8AAADAifhk017d9to69ercVm9MGa72kSG2JwGANYQfDxUWHKiHr+inPzSe+zPxyRXaVsS5PwAAAMDxvP91gW5/I1P9u0TrtVuGql1EsO1JAGAV4ceDOY6jm0Z11Wu3DNPBqnpNfGKFFnLuDwAAAHBMb6/drbvf+lrDusZq9s1DFRVG9AEAwo8XGNE9Vh/ecYZS4iI05dW1+vvCHM79AQAAAI7y+qqdeuCdjTqjR5xeunGIIkODbE8CAI9A+PESidHheufWkZo0IFGPLszWra9x7g8AAAAgSS+v2KHfvveNRvfsoOd/OVjhIYG2JwGAxyD8eJGw4EA9fOXhc38WbeXcHwAAAODZZdv03x9u1vmnddTT1w1SWDDRBwCORvjxMsc692fRFs79AQAAgP95bFGO/vzpVl3Sr7Mev2aAQoJ4egMAP8ZXRi81onusPrh9lFLiInTL7LV6bBHn/gAAAMA/GGM0c16WHlmQrckDkzTrqv4KDuSpDQAcC18dvVhS+wi9c+tIXTYgUY8sOHzuT0Vtg+1ZAAAAQIsxxujPn27VE0tydfXQLnro8r4KDHBszwIAj0X48XJhwYF65Mp++n8Xf3/uz3bO/QEAAIAPcruN/uuDb/Xc59t1w4gU/e/EPgog+gDAcRF+fIDjOLr5jK6ac8tQlVTWaQLn/gAAAMDHuN1Gv/3XJs3+aqemntlV/3XpaUQfAGgCwo8PGdk9Th/cPkrJsRGa8upaPc65PwAAAPABLrfR/e9s1Jurd+v2c3voPy/sJcch+gBAUxB+fExS+wi9e9tITeyfqIcXZOu21zn3BwAAAN6r3uXW3W99rXcz83Xv2HTNGJ9B9AGAE0D48UHfnfvz+4t7a+EWzv0BAACAd6prcOuON9brww179OAFPXXn6DTbkwDA6xB+fJTjOLql8dyfAxW1mvDkCi3eyrk/AAAA8A419S7d9to6ffbtPv3hkt669ezuticBgFci/Pi4kd3j9OEdZyg5JkK3zF6rJxbnyBjO/QEAAIDnqq5zaeqra7Voa6H+97LTddOorrYnAYDXIvz4gaT2EXrn1pGa0K+zZs7P1m2vZXLuDwAAADxSZW2Dbn5ljb7ILdbfLu+ra4el2J4EAF6N8OMnwkMC9ehV/fW7i3ppwZb9uuzJFdpRXGl7FgAAAHBEeU29bnhptVbnlWjWVf115eAuticBgNcj/PgRx3E05cxumnPzUBVX1OrSJ77Qkq2FtmcBAAAAKquq13UvrtbXu0v1+NUDNKF/ou1JAOATCD9+aGSPOH1w+xnq0j5CN89eoyeX5HLuDwAAAKw5WFmna15YqS17Dunp6wbpwj6dbE8CAJ9B+PFTXWIi9O5tI3Vpv856aF4W5/4AAADAiuKKWl39/ErlFlbouV8O0tjeCbYnAYBPIfz4sfCQQM1qPPdn/uZ9nPsDAACAVrX/UI2uevYr5R2o1Es3DtE5GR1sTwIAn0P48XNHzv25Zdj35/5kce4PAAAAWtae0mpd9exX2ldWo9k3DdWoHnG2JwGAT3Ja82yXwYMHm7Vr17ba58OJ2V1Spelz1mnLvkOaMS5DvzqnuxzHsT0LgGXGGDW4jWrqXaptcKum3qWaerdqG75/rP3R28d/dKu23qVh3WJ1/fAUhQTx/yAAwN/sLqnS1c+vVFl1vWbfPFQDk9vbngQAXs1xnHXGmMHH/D7CD45WXefSb97dqA827NEFp3fUzCv6KTI0yPYsADocYOpd5rhh5VgB5uhgc7zH2uN8v/sU/lURGOAoLChAocGBRx4laUdxpVJjI/QfF/bSuN4JhGYA8BM7iit17fMrVVnn0mu3DFOfpHa2JwGA1zte+OEZPX4gPCRQf/9Ff/VJbKc/f7pF24oq9Nz1g5UaF2l7GuAxfhxgTiSgNDXA/FTYaY4AExYcqNDGx5Cj3o6OCDny/p98DA5QWNDhx9Cg798Oa3w7LPiHgScsKEBBgce+omdpVqH+9PEWTZ+zTsO7xej3F/fWaZ35j38A8GW5heW65vlVanAbvTl1uHp3bmt7EgD4PK74wU/6IqdYt7+ZKbfb6LGrB3DYHjzOdwGmpvFKlxMJMD/3kqSfe+nSqQSYoADn34JKyE+Elh8ElWM8hh7v+5sYYGxqcLn1xupdenRBtkqr63XFoCTNGJehDm3DbE8DADSzrfsO6drnVykgwNEbU4YpLSHK9iQA8Bm81AsnbXdJlabNWaetnPsDD3Copl6fbNyruZkF2lRQ1iwB5sexJfTI28cPLscKMMe9UuaoR08MMLaVVdXr8cU5mv1VnoIDA/Trc3voljO6KqzxZWEAAO/2TUGZrntxlcKCAvXG1GHqFt/G9iQA8CmEH5ySo8/9ubBPRz10Oef+oPU0uNxanlOsdzPztWDzftU2uNU9PlJnpcerTWjQT0QbAoy32lFcqT9/skXzN+9XYnS4fnNBT13StxPBGQC82PpdB3XDS6sVFRasN6cOV3JshO1JAOBzCD84ZcYYvbB8h/786RaldYjSc78cpJRYzv1By/l2T5nmZhbo/a/3qLiiVu0jgnVpv86aNDBJfZPaEQJ83JfbivXHj7Zoy95DGpgcrd9f3FsDuOMLAHidNXkluunlNYptE6LXpwxTUnuiDwC0BMIPms3ynCLd8eZ6zv1Biyg8VKP3v96jdzPztXVfuYIDHY3umaBJAxN1TkYHbvvtZ1xuo3fW7dZD87JVXFGrCf076zfn91Tn6HDb0wAATfDltmJNmb1WHduF6Y0pw9WxHee3AUBLIfygWe0uqdLUV9cqa3+57h+fodvO5twfnLzqOpfmb96nuZkFWp5TJLeRBiRHa9LAJF3cp5PaR4bYngjLKmob9PTSXD2/fIccSdPP6qbpZ3fnJacA4MGWZRdp2qtrlRIbodemDFOHKKIPALQkwg+aXVVdg37z7iZ9uGGPLurTSX+7vC9PwtBkbrfR6rwSzc3M1yeb9qmitkGJ0eG6bECiJg1M5MBHHFP+wSr99bMsfbhhjzpEher+8RmaPDBJAQGEZwDwJIu27Ndtr2WqR4c2em3KMMXwP3EAoMURftAijDF6fvl2/eXTrZz7gybZXlSh99YXaG5mgQpKqxUZEqgL+3TSpIFJGtY1hifwaJJ1O0v0Px9t0YbdpTo9sa1+f1FvDesWa3sWAEDSZ9/s1R1vrlevTm316s1DFR1B9AGA1kD4QYtanlOk299YL0l67OoBOjs93vIieJLSqjp9tHGv5mbmK3NXqQIc6Yy0eE0emKhxvTsqPITbdePEud1GH2zYo79+tlV7y2p0/mkd9R8X9iQ+A4BFH2zYo3ve+lr9ktrplZuHqm1YsO1JAOA3CD9ocbsOVGnanLXK3l+u+8f31K1nd+PcHz9W1+DWsuwizc3M16IthapzuZWe0EaTByZp4oBEJbTldf5oHtV1Lj2/fLueXrpNLrfRTaNS9evzevBkAwBa2Tvr8vXAOxs0JDVGL944RG04AgAAWhXhB62iqq5BD7yzUR9t3Mu5P37IGKNNBYdvwf7Bhj0qqaxTXJsQXdrv8Lk9p3VuSwxEi9l/qEYPzcvSO+vyFRsZonvGpusXQ7ooKJA7wQFAS3tz9S7953ubNKp7nJ7/5WCu5gUACwg/aDXGGD33+Xb99bOtSk+I0nPXD1ZybITtWWhBe8uqj5zbk1tYoZCgAI3tnaDJAxN1Zlq8gnnijVa0Kb9Mf/xos1bnlSg9oY1+d1FvncXLTwGgxcz+Mk9/+OBbnZsRr6evG6SwYKIPANhA+EGr+zy7SHe8efjcn8evHsATLx9TWduged8evgX7im3FMkYanNJekwcl6cI+ndQunJfZwB5jjD77Zp/+79Mt2l1SrXMz4vXbi3qrRwfuFgcAzen5z7frfz/ZonG9E/T4NQMUGkT0AQBbCD+w4uhzfx44v6emn8W5P97M5TZauf2A3s3M12ff7FNVnUtdYsI1aUCSJg1M5FBdeJzaBpdeWZGnJxbnqqrepeuHp+iu0Wlqz22FAeCUPbE4RzPnZ+uivp0066r+XOELAJYRfmBNVV2D7n9noz7euFcX9e2khy7vq4gQzv3xJrmF5Xo3s0D/Wl+gvWU1igoN0sX9Dt+CfXBKe2IePF5xRa0eXZCtN1fvUlRYsO4cnabrh6coJIgnKQBwoowxenRBth5bnKvLBiTqocv7cp4aAHgAwg+sMsbo2c+362+c++M1Sirr9OGGPXo3M18b88sUGODo7PR4TRqYqDG9Enj9PrxS1r5y/enjzVqeU6yucZH67YW9NLpXB+IlADSRMUZ/+Wyrnl22XVcN7qL/m9RHgQF8DQUAT0D4gUc4+tyfJ64ZoDPTOPfHk9Q2uLRka6HezSzQkq2FanAb9e7UVpMGJmpC/0TFR4XangicMmOMlmQV6k8fb9H2okqN6hGr313UW706tbU9DQA8mjFG//PRZr28Ik/XD0/Rf196mgKIPgDgMQg/8Bg7D1Rq+px1nPvjIYwxWr+7VHMz8/Xhhr0qq65XfFSoLhuQqMsGJPJkGD6r3uXW6yt3ataiHB2qrtdVQ7ro3rEZBE4AOAa32+j373+j11ft0i1ndNXvLurFf78BgIch/MCjHH3uz8V9O+lvnPvT6naXVOlf6ws0d32BdhRXKiw4QONP66hJA5M0qnssr9WH3yitqtNji3L16ld5CgsO1K/O7a6bR3Xl5YwA0MjlNnrw3Y3657p83XZOdz0wPoPoAwAeiPADj2OM0TPLtutv87YqIyFKz/9ysLrEcO5PSyqvqden3+zT3Mx8rdxeIkka1jVGkwcl6YLTOyoqjFuww39tL6rQ/32yRQu3FCqpfbj+44JeurBPR57cAPBrDS637vvnBr3/9R7dPSZNd41O4+siAHgowg881rLsIt3xRqYCAhw9fjXn/jQ3l9voi9xizc3M17xv96mm3q2ucZGaNCBREwckEtuAH1mRW6w/frRZW/eVa0hqe/3uot7q1yXa9iwAaHX1Lrfu+sd6fbJpnx44P0O/OqeH7UkAgOMg/MCj7TxQqWmvrlNOYbl+c35PTePcn1O2dd8hzW28BXthea3ahQfrksZbsA/oEs3vL3AcLrfR22t36+H5WSquqNOkAYm6//wMdWoXbnsaALSK2gaXfv36ei3csl+/u6iXppzZzfYkAMDPIPzA41XWNuiBdzbq4017dUm/zvrr5D6c+3OCispr9cGGPXp3Xb427z2koABH52R00OWDEnVuzw4KDeLMEuBElNfU66ml2/TiFzsU4EjTz+qu6Wd342sTAJ9WU+/S9DnrtCy7SH+ccJquH5FqexIAoAkIP/AKR5/707NjWz13/SBeivQzaupdWrhlv+ZmFmhZdpFcbqO+Se00aUCiLunXWbFtuEMRcKp2l1TpL59u1ceb9qpj2zA9cH6GJvZP5DbGAHxOVV2Dpr66Vl9uO6C/TOqjq4Yk254EAGgiwg+8ytKsQt355noFBDh64uqBOiMtzvYkj2KM0dqdBzU3M18fbdyr8poGdWwbpssGJmrSgESlJUTZngj4pDV5JfrjR5u1Mb9MfZPa6fcX99aQ1BjbswCgWVTUNujml9do7c4SzbyinyYNTLI9CQBwAk4p/DiO00XSq5I6SnJLes4Y83fHcWIkvSUpVVKepCuNMQeP93MRftBUecWVmj7n8Lk/D17QU1PP5NyfXQeqNHd9vuZmFmhXSZUiQgJ1/ukdNXlgkoZ3i1UgVx8ALc7tNvrX1wX622dZ2neoRhf16aQHL+jJ1YkAvFpZdb1ufHm1NuaX6e+/6K+L+3a2PQkAcIJONfx0ktTJGJPpOE6UpHWSJkq6UVKJMeYvjuM8KKm9MeY3x/u5CD84EZW1Dbr/nQ36ZNM+Xdqvs/46ua/CQ/zrnJqy6np9smmv5mbma03eQTmONLJ7rCYNSNL5p3dUZChnjQA2VNU16LnPt+vZZdvlMkY3j+qqX5/bXVFhwbanAcAJKa2q0/UvrtbWfYf0xDUDNf60jrYnAQBOQrO+1MtxnPclPdH41znGmL2NcWipMSbjeD+W8IMTZYzR08u26aF5WX5z7k+9y63lOUV6N7NACzbvV12DW93jIzV5UJIm9k9U52juLAR4ir1l1XrosyzNXV+guDYhum9chq4c3IUr8AB4hQMVtbr2hVXaXlypZ64bqPN6JtieBAA4Sc0WfhzHSZX0uaTTJe0yxkQf9X0HjTHtj/fjCT84WUuyCnWXD5/7Y4zRt3sO34L9gw0FKq6oU/uIYE3on6hJAxPVJ7Gd37/UDfBkG3aX6o8fbdbanQfVs2OUfn9xb43q4VtfpwD4lsJDNbr2hVXafbBKz/9ysM5Mi7c9CQBwCpol/DiO00bSMkn/a4yZ6zhOaVPCj+M40yRNk6Tk5ORBO3fuPJlfA6C84kpNm7NWuYUV+o8LemnKmV29PobsP1Sj978u0LvrCpS1v1zBgY5G90zQ5EFJOjs9XiFBAbYnAmgiY4w+2bRPf/50i/IPVmtMrw76zwt7qVt8G9vTAOAH9pZV69rnV2nfoRq9dOMQDe8Wa3sSAOAUnXL4cRwnWNJHkuYZYx5pfF+WeKkXWtnR5/5M6N9Zf5nkfef+VNe5NH/zPr2bWaAvcorkNtKA5GhNGpikS/p2UnREiO2JAE5BTb1LL63YoaeWbFNNvUvXj0jRXaPT+GcbgEfYXVKla15YqdLKer1y8xANSuHuhADgC071cGdH0mwdPsj57qPe/5CkA0cd7hxjjHngeD8X4ef/t3fnYbKddZ3Af2939X73JcvdE7JekJibGMIiiBgNhAEN4/MIDA8ukfFxVHRUBhD9R8VllBEfcUYGEBEQGYkORsIikBlUyGQjkOQmJCQ3uUtyl07u1svtpc78caq7q6q7erndt+veU5/P89RTdU69p/rte7vqnPqe3/selkKWZfHnd3w3/uiLj8SVF6yKvzgH5v0pl7O484ln49Z798XtDzwTJ0+NxeY1PXHzrs3xY1dvVhEABXT4xKl435ceib+9a2+s6umIX37VpfHm67dHR7tKPqA59hwZiDd/6M44MTwaf/0zL4qrtq6ZeyMAzgmLDX5eFhFfi4hvR34594iId0fEnRHx6YjYFhFPRcSPZ1n27GyvJfhhKU3M+9PeluLP3rTrrJxP4/HDJ+PWe/fH39+3P/YfHYoVXaV4zfdcEDfv2hLX7VgXbSaAhcLb/fTx+J1/eij+9bH+eN7GvviNm66MV15+3jk/VBU4tzx26GS8+UPfiJGxcnz8lhfF8zetbnaXAFhCS3pVr8UQ/LDUquf9efdrroyfeVnz5/05OjgS//it/BLs9z11NNpSxMsu3Rhv2LU5fnjnBefc0DRg8bIsiy/vPhTv/dzuePzIQHz/pRviPTftjMsvWNnsrgEt4JFnTsSbP3RnRGTxiVuu99kDUECCHwrt5Kmx+PX/dX/c/sAz8aPfuyl+rwnz/oyMleOORw7Frffujy8/fDBGx7O4/PyV8YZrNsfrv3dznL+qe1n7A5ydRsbK8dffeDLe/8/fiZOnxuInrtsW//mGy2LDiq5mdw0oqAf2H4u3fPjO6Cy1xSduuT4uOc/wcoAiEvxQeM2Y9yfLsvjWvmNx67374rP3H4jnBkdjw4rOyUuw77xwVdOrj4Cz03MDI/H+Lz8af/2NJ6O3oz1+4QcviZ986Y7oKqkIBJbO/XuPxls+fGes6CrFJ3/2+tixoa/ZXQLgDBH80DK++vCh+KVP3RelthQfeNOueMkZmPfnwNGh+Idv7o9b790fjx06GZ2ltrhh5/nxhl2b4/sv3WjiVmDeHjt0Mt77ud3xlYcPxbZ1vfGuV18RN77gAqExsGj3PPls/ORH7oo1fR3xyVuuP+svhAHA4gh+aClPHBmIt33s7nj8yEC869VXLMm8PwOnxuLzDzwTt963L/7tu/2RZRHft2Nt3LxrS7zmey6M1T0dS9R7oBV97dHD8Tu37Y5HDp6I6y5aF7950874ni0mXgVOzzce74+f/uhdcf6q7vjkz74oLlzd0+wuAXCGCX5oOSdPjcWvffr++PyDpz/vz3g5i69/t3/yEuxDo+OxbV3v5CXYt69XLg0snbHxcvzt3XvjfV/8Tjw7OBI3X70l3nHj5eYIAxbkXx49Erd87K7YurY3PnHLi+I8nyEALUHwQ0sql7P48zseiz/+0ndi54X5vD9b1s5d5vzowRPxmXv3xz/ctz+eOT4cK7tL8doXboo37Noc12xfawgGcEYdHx6ND3zlsfjLf90T7W0pfu4Vz4u3vfxiVwQE5vTVhw/Ff/z4PXHxhr74+C0vMnE8QAsR/NDSvvLwwXj7p74ZHe1t8Wdvujpe8rzp8/70nzwV/3j/gbj1vv3xrX3Hor0txSsu2xg379ocP3Tl+dHd4QsXsLye6h+M37t9d9z+wDNx4eru+C83XhGvu2pTtLUJn4HpvvDgM/ELn7w3rrhgVXzsp6+LtX2dze4SAMtI8EPLq573592vuTJ++qU7YmS8HF/ZfSg+c+/+uOORQzFWzuL5m1bFzbu2xOuu2hQbVzpLBjTfnY/3x2//00PxwP7jcdXWNfFbr70yrtm+rtndAs4it33rQLz9U9+MF25ZHR/9qevMPQjQggQ/EPm8P7/66W/GFx48GNftWBePHDwRx4ZG47yVXfFjV2+OH9u1Oa64YFWzuwkwTbmcxa337Y8//PzDcejEqXjtCy+Md776inkNXwWK7e/v2xe/+un749rt6+IjP/V9saKr1OwuAdAEgh+oKJez+MBXH4uP3/lkXH/x+rh515Z42SUbot3QCeAcMHBqLP7i/3w3Pvi1x6OcRdzysovi5195iS960KL+9q6n4p23fjtefPH6+NBbr43eTp8FAK1K8AMABXLg6FD84ecfjn/45oHYsKIrfv1HLot/f81WITZnpSzLIssiylkW5Swii9rlcpZFVp5YbtCmXL2cr4uY2r5c2b5hm3Lldat+ZjnLIqv0r1yu6l9dm4hGP2NiOX+diZ/RsE0WNcvlrPZnTn+NGdpULQ+NjsXnvv1MvOKyjfEXb7nGfIQALU7wAwAFdN9Tz8Vv3/ZQ3PvU0dh54ap4z2uvnHECe1rb2Hg5Dhwdjif6B+LJ/oF44shAPNk/GAePD8d4VaCSxQzhSbk2CJkMSiYDlxlCjro2y3ioec5IKaItpWhLEalyny+nSCkiRURbW5q9TYq4bsf6eO/NL4iuktAHoNUJfgCgoLIsi9u+9XT8/u0Px/6jQ3HDzvPj3a+5Mi7a0NfsrrGMxsbLse+5odjTn4c6ebgzEHv6B2Pvs4MxVp463uvtbI/t6/ti0+ruKLWnSJGirW0iXJgKGCbCiRSVwKFt5gBisk1bqgk08ucrwUVU1s3aZuL56p8x1a/8+dptGrWZ9Xdpq91mWpsZXre6TZphm+r203+/6W0AYKkJfgCg4IZHx+PD//JE/PlXH4uR8XK89cU74hdfdamr+xTIaFW4s6dStTPxeN9zQ9PCnR3r+2LHht78fn1f6n4H8QAAF/NJREFUbF/fGxdt6IuNK7uEDwBQMIIfAGgRh04Mxx9/4Tvx6Xv2xpqejviVGy6LN123LUrtbc3uGvMwMlaOfc8N1lTtPNE/GE/25+HOeFW409fZHjs29OW39b2xfX1fXLQhD3g2rhDuAEArEfwAQIt58MCx+J3bdsfXH++PS85bEb9x05XxysvPa3a3iDzc2fvcYOw5kg/Fqp53Z//R2nBnRVeppmqnOuTZsKJTuAMARITgBwBaUpZl8aWHDsZ7P7c79vQPxssv2xjvuenKuOz8lc3uWuGdGhuPvc8OVcKdgcm5d/b0D8T+54aiKtuJld2lSqVOHupUD9Fa1yfcAQDmJvgBgBY2MlaOj319T7z/y4/G4Mh4vOm6bfErN1wW6/o6m921c9rw6HjsfXZwWtXOE0cG4sCxoZqrWa2qDnfqhmat7e0Q7gAAiyL4AQDi2YGR+JN//k584s6norezPX7pBy+Nt75kR3SWzP/TyPDoeDz17GBV5U4e8uw5Mjgt3FnT2zFj1c6O9X2xVsgGAJxBgh8AYNKjB0/E735ud9zxyOHYvr433vXqK+NHnn9+y1adDI+O11wha0//YOWqWQPx9PHhmnBnbSXcmZhEuXrenTW9wh0AoDkEPwDANHc8cih+9592x6OHTsb1F6+L99y0M16weXWzu3VGDI2Mx5PPDsw4ofLTx4Zr2q7r65ys2tleV7mzurejSb8BAEBjgh8AYEZj4+X4m//3VLzvS9+Jo0Oj8ePXbIlf++HL47xV3c3u2oINjozllTtVVTsTkyo/c7w23Fnf1xk7KlU7F63vi+1V8+6s7hHuAADnFsEPADCrY0Oj8WdfeTQ++m97oqO9LX7+B54Xt3z/xdHd0d7srtUYODVWc4Ws6pDn0IlTNW03rOiqmkR5ajLlbet7Y1W3cAcAKA7BDwAwL3uODMTv3b47vvDgwdi8pifecePl8bqrNi3r/D8nT41V5tiZCnee7B+MJ/oH4nBduLNxZVfVZMpT8+5sX98bK4U7AECLEPwAAAvy9e/2x2/f9lA89PTxuHrbmvjN1+6MXdvWLtnrnxgenbFqZ0//YBw5WRvunLeya/IqWdUTK29f3xcrukpL1icAgHOV4AcAWLDxchafuWdf/NcvPhKHT5yK13/vpnjHjVfE5jU989r++PBoPHkkr9R5ciLc6c+vlnXk5EhN2/NXdU1OoLx9Q2XenUrlTp9wBwBgVoIfAOC0nTw1Fv/jju/G//za4xER8baXXxw/94rnRV9XKY4NjdZcIat6QuX+gdpw58LV3dMugb5jQ19sW9cbvZ3CHQCA0yX4AQAWbf/RofiD2x+Oz95/INZWLmv+3OBoTZtNq7srl0Dvq5pYOQ93ejrPromiAQCKYrbgx+k1AGBeNq/piT9949Xx1pfsiI/+255Y2V2qmVh527res+4qYAAArU7wAwAsyDXb18Y125duomcAAM6ctmZ3AAAAAIAzQ/ADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABSX4AQAAACgowQ8AAABAQQl+AAAAAApK8AMAAABQUIIfAAAAgIIS/AAAAAAUlOAHAAAAoKAEPwAAAAAFJfgBAAAAKCjBDwAAAEBBCX4AAAAACkrwAwAAAFBQgh8AAACAghL8AAAAABSU4AcAAACgoAQ/AAAAAAUl+AEAAAAoKMEPAAAAQEEJfgAAAAAKSvADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABSX4AQAAACgowQ8AAABAQQl+AAAAAApK8AMAAABQUIIfAAAAgIIS/AAAAAAUlOAHAAAAoKAEPwAAAAAFJfgBAAAAKCjBDwAAAEBBCX4AAAAACkrwAwAAAFBQgh8AAACAghL8AAAAABSU4AcAAACgoAQ/AAAAAAUl+AEAAAAoKMEPAAAAQEEJfgAAAAAKSvADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABSX4AQAAACgowQ8AAABAQc0Z/KSUPpJSOpRSeqBq3bqU0pdSSo9W7tee2W4CAAAAsFDzqfj5aETcWLfunRHx5SzLLo2IL1eWAQAAADiLzBn8ZFn2fyPi2brVr4+Iv6o8/quI+NEl7hcAAAAAi3S6c/ycn2XZ0xERlfvzlq5LAAAAACyFMz65c0rpbSmlu1NKdx8+fPhM/zgAAAAAKk43+DmYUrowIqJyf6hRwyzLPphl2bVZll27cePG0/xxAAAAACzU6QY/n42It1YevzUi/vfSdAcAAACApTKfy7n/TUR8PSIuTyntSyn9TET8fkTckFJ6NCJuqCwDAAAAcBYpzdUgy7I3NnjqVUvcFwAAAACW0Bmf3BkAAACA5hD8AAAAABSU4AcAAACgoAQ/AAAAAAUl+AEAAAAoKMEPAAAAQEEJfgAAAAAKSvADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABSX4AQAAACgowQ8AAABAQQl+AAAAAApK8AMAAABQUIIfAAAAgIIS/AAAAAAUlOAHAAAAoKAEPwAAAAAFJfgBAAAAKCjBDwAAAEBBCX4AAAAACkrwAwAAAFBQgh8AAACAghL8AAAAABSU4AcAAACgoAQ/AAAAAAUl+AEAAAAoKMEPAAAAQEEJfgAAAAAKSvADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABSX4AQAAACgowQ8AAABAQQl+AAAAAApK8AMAAABQUIIfAAAAgIIS/AAAAAAUlOAHAAAAoKAEPwAAAAAFJfgBAAAAKCjBDwAAAEBBCX4AAAAACkrwAwAAAFBQgh8AAACAghL8AAAAABSU4AcAAACgoAQ/AAAAAAUl+AEAAAAoqFKzOwAAAADnjCyLGD4acfJQRHtnRGdffiv1RLSpreDsI/gBACiC8njE2HDE6HB+X3M7FTE6lN+PVe7LY/kXllJXRHtXfl/qiih1V9Z3R5Q665a7Itram/2bApxZ5fGIkwcjju6NOLY34uhTEcf2VR7vzR+PnJh5246+iM7eShi0IqKjdyoY6uyrWl4x1a5j4vneyvqJdpU2HX0CJRZF8AOce8ZH8zMtpc5m9wSgVpZVwpU5QpeagKbR+pm2n+V1y2PL8zu2leqCojmCoxnbzhQqTSzP87XbHcYCp2l0uBLkVAKdiYDn2L485Dl+IKI8WrtN95qINVsj1l0UcdHL88crLsjbjQxM3UYHI0ZORowMVpYH8uWTB2vbjA4urM+lntoAqT4cqgmQZmlTH0YJ81uCPeZClcsRJw5UDlC6HXhAvYkvPRM7tJHBmR9PLg/lO8TRocqOcKjyXNXj+rYTX27auyK6Vk7dulfXLk/eVjVYV1lf6opIqbn/bsDSGh+dZ+iyxAHN2PDi+t1Wqj3GKHVFdPRUQo+e/HOudH5ER9XzpZ6pUKSje5bt69a3lSLGR/Lb2HDEWOV+cvlUfhs/NfV42vLwzNsPH61artt+bDgissX/H6e20wiOFljd1HD7qvZtJfsQOJtkWcTQc3UVOntrHw8crtsoRay8MA9ztnxffr96S8TqbVOPu1YubT/L5alj3pGTVY8bBEiN2gz2160bWFg/St1V4VDf/KuQZq1oWuE78lnG/8ZCDR+N+G/Pr103eZBWdfBVfZA2r4Ox+u2q2s10cNfRkx+YONBgocrl/IvLvEKYwemBzLQAp67t6GBEVl5Yn9pK+c6lo6dSzjpx64no25DfT+xUOnrythF5ie2putuxvfn98PGIU8fndwa8rWP2kKh71RwBUuVxR6/3JFQrl+cIV85gVUw2vri+z7pf7onoWTvLfn6O/Xqjtq1yMinL8s/mmiBppuCpQXA0n+BpYnn4+CzbDy98fzWjdPrB02JDqc4VeRho30MrKY9HnHimtkKnegjWsb15SFKt1F0JcrZGnP/8iDXb8sert+TBzqrNEe0dy/t7tLVFdK3Ib3H+0r1u9bF+TVhUX4U0MHuboeeq2lS2WchnZnvXVGhUHw6dbrVSR1+o+D89LXB0scQ6eiL+3Z/OfQBafaA6fLTxAe2iyrJT1c7/DARL0w5oqx4rCTxzyuNVQctECDM4c1XMrBU1DdqODS28T+2Vv4mJD+CJx92r87MjHb21gU1NeDOx3FMV7kwEOJUP8TO1o52oPjp1Ig+B6kOiU8cbrD8RcfKZiP5Hp5bncxY/tc8SEM0QFDUKlIzjZqllWaUCZqiyfxqq3W+NDlXdn1pAu/r9Xt268ZHF9bvmS+4MAUvv+ln2gQ32g7OFLhPrnVg5s1LKP/fbOypfeJpofGweQdJswdN8gquR/MvUYH/j7RdzPNjWkZ8k6dsQ0Vu579uYvz/6Ntat35Dvc/x9czYbHYo4tj8fhlUzBGtvvu74genvmZ61eYiz7uKIi19RG+qs3pb/7bfK331b21RwEhuX7nWzLP9MO52qpOo2xw9Utak8t5CTNW0dcwxlm6FaadZ5lfryv5+C/32kLFuCUtt5uvbaa7O777572X7eOWF8bI4zng3Ods6nbH3G7SYOxk8trt9tHTMfaNccTNevm6ndAkOq9o7mviknvjzVBDINqmbmE8LM9Dqn80Wpoz5YaRTCVIcu1W1nCGQmti31tMYZ6LmMjcwRIM0zVJrXeO40x3C1OSqPJgKlzhVC2rNRluXv84kQZfLzuipsmfycH5693Wj9Z36DoGaxlQ3VlS41n+OnMcRoIUOU/P3SKsrj86hgmiF4OnU8YuBIxOCR/H7gSD6EZbB/esXDhPbO2iCotxIU9VWCourl3g35/qTgX4hYRpPDsOoqdKonT64fhpXa8hONq7dWDcHaWqna2XJmhmGxfCaOi6rDopqqpEYh01yVSwPzrPwvRfxW/5n/PZdBSumeLMuunek53+aarb0U0b5i+c94lctTZ6hmLZevD5rmCpYq9xNntepff3QoFjWuf2I8/2KH1bWX8n7NFcLMNO/MQocPpLbGw5h6Nk+FMNOqYmapmql+rtStOmQ5lDojSuvzA+HFGB+bPkRteJbKo4n1w8fyA6KJ5UYH9PU6V8xReVQfIjUIlYoa/k1OxLuAsGXWdvPcdjGfg6We2tBlIozp6MknnlxRFcp01Acus2w7Wztf+uDMamuvnIXuXbrXHB1qEApVLQ8eieh/LGKgv/G8IO1dM4REG2oriiYrjDbk+x2fGa2rPB5x4unaCp36yZNnHIZVCXQueEFeoTNZrbM1YtWm5R+GxfJJKSaHr/auW9rXHhuZe1jbYquTzxEFPZJnTm1tEW09lfBhGX/u5HCD06hgmrOqaTh/Aw8cmTnIqp+Zf/LfomPmoUqdfRF9580SwsxjGFNHry9N1Gov5eWkPWsX9zrl8fzvfbbKo+HjM68/cbB2m/mEEKWeqqFps4VEdRNn17edbVz2RAnxaVfAnGZQc9ohTJo9MOleE7GyJ6ZVx8w3bJmpnc8TYL46evIvzmu2zq/9yGAlFDqcB0GTj4/UBkhHHs3XNxo6XuqurSiqDoXqK4r6NlaGo3DOGB2qmldnhsmTGw7D2hqx/pKIi3+gqnKncmulYVgsr1JnflvscXcBCH5YXilNvQGXW3l8KggaH5kKZ5xB4FzU1p7PsdS9enGvM3FFiZpwaI7hbBOB0sATtc/Npxqu+kpsEdPDmNOV2mYPTHrXnX7Y0qideWCAIunsjejclg+fmY+RgemhUH1F0cDhiMOPVIKiBp/xpZ45hp3VPbeUVVHUmhiG1SjUObo3//+tltoiVm7Kg5ytL5oe6qze0vy5vADBDy2krb1qojMgIuquKLEIWZYHONOCogaB0vDxShDcvbgKmInnmz3/F0CrmTimWrt97rZZlgdFcw07GzgUcWh3/lyj+Sg7emefyLq+wqhjOUvbz3ITw7Bmurz5xHCs+iF/pZ6pYVcXvLAu2NliGBacIwQ/ACxeSlPzU6xcwkuSAnDuS2nqJMPaHXO3z7Kp4fuTodAMw85OPBNx8MFKUNRgno6OvrphZxtmnsh6Yrmje0l/9WU1MjhVqTNt8uS9Ecf3T6/O7VmXBznrL4m4+JW1oc6abXmI5sQKnPMEPwAAwNkjVV3dct1Fc7fPssoQ5MoVzRoNOzu+P+Lpb+WPG8392Lli+rCz6kmt6ye5LnUt7e8+2+84OQyrOtR5aurxbMOwtl1fdUWsbfnjVZsNw4IWIfgBAADOXSnlFyDoXhWx/nlzt8+yfPjxrMPODudhyoH78uVGl4XuXDnDRNYb64ajVVUbNZrncnyscjWsvVWTJ1cNwTq2b+ZhWBMVOhdeVXlcdUWslZuKe1VOYEF8EgAAAK0jpakLJMw3KBo+Nvuws4HDeViz/5686qhRUNS1eqqKqHd9/rrH9s08DKt3fR7ibLg04pJXVap1tk4FPL3rDMMC5kXwAwAA0EhKET1r8ltcMnf7cjli+Ojsw84Gj+QVPV2rIra/uC7UqQzJckESYIkIfgAAAJZKW1tejdO7Lq/WAWiytmZ3AAAAAIAzQ/ADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABSX4AQAAACgowQ8AAABAQQl+AAAAAApK8AMAAABQUIIfAAAAgIIS/AAAAAAUlOAHAAAAoKAEPwAAAAAFJfgBAAAAKCjBDwAAAEBBLSr4SSndmFJ6JKX0WErpnUvVKQAAAAAW77SDn5RSe0R8ICJeHRE7I+KNKaWdS9UxAAAAABZnMRU/10XEY1mWPZ5l2UhEfCoiXr803QIAAABgsRYT/GyOiL1Vy/sq6wAAAAA4Cywm+EkzrMumNUrpbSmlu1NKdx8+fHgRPw4AAACAhVhM8LMvIrZWLW+JiAP1jbIs+2CWZddmWXbtxo0bF/HjAAAAAFiIxQQ/d0XEpSmli1JKnRHxExHx2aXpFgAAAACLlbJs2uis+W+c0msi4k8ioj0iPpJl2e/O0f5wRDx52j/w7LIhIo40uxPQwrwHofm8D6G5vAehubwHOZtsz7JsxmFWiwp+WllK6e4sy65tdj+gVXkPQvN5H0JzeQ9Cc3kPcq5YzFAvAAAAAM5igh8AAACAghL8nL4PNrsD0OK8B6H5vA+hubwHobm8BzknmOMHAAAAoKBU/AAAAAAUlOBngVJKN6aUHkkpPZZSemez+wOtJqW0NaX01ZTS7pTSgymltze7T9CKUkrtKaX7Ukq3Nbsv0IpSSmtSSn+XUnq4sk98cbP7BK0kpfQrlWPRB1JKf5NS6m52n6ARwc8CpJTaI+IDEfHqiNgZEW9MKe1sbq+g5YxFxK9mWXZlRFwfEf/J+xCa4u0RsbvZnYAW9v6I+HyWZVdExFXh/QjLJqW0OSJ+KSKuzbLsBRHRHhE/0dxeQWOCn4W5LiIey7Ls8SzLRiLiUxHx+ib3CVpKlmVPZ1l2b+XxicgPdDc3t1fQWlJKWyLipoj4ULP7Aq0opbQqIl4eER+OiMiybCTLsqPN7RW0nFJE9KSUShHRGxEHmtwfaEjwszCbI2Jv1fK+8IUTmialtCMiro6IO5vbE2g5fxIR74iIcrM7Ai3q4og4HBF/WRly+aGUUl+zOwWtIsuy/RHxRxHxVEQ8HRHHsiz7YnN7BY0JfhYmzbDOZdGgCVJKKyLiMxHxy1mWHW92f6BVpJReGxGHsiy7p9l9gRZWiohdEfHfsyy7OiIGIsLck7BMUkprIx/5cVFEbIqIvpTSf2hur6Axwc/C7IuIrVXLW0JJHyy7lFJH5KHPJ7Isu7XZ/YEW89KIeF1KaU/kQ55/MKX08eZ2CVrOvojYl2XZRMXr30UeBAHL44ci4oksyw5nWTYaEbdGxEua3CdoSPCzMHdFxKUppYtSSp2RT+D12Sb3CVpKSilFPqfB7izL3tfs/kCrybLsXVmWbcmybEfk+8GvZFnmLCcsoyzLnomIvSmlyyurXhURDzWxS9BqnoqI61NKvZVj01eFCdY5i5Wa3YFzSZZlYymlX4iIL0Q+c/tHsix7sMndglbz0oh4S0R8O6X0zcq6d2dZ9rkm9gkAltsvRsQnKicjH4+In2pyf6BlZFl2Z0rp7yLi3sivOHtfRHywub2CxlKWmaIGAAAAoIgM9QIAAAAoKMEPAAAAQEEJfgAAAAAKSvADAAAAUFCCHwAAAICCEvwAAAAAFJTgBwAAAKCgBD8AAAAABfX/AduToxhXWhGYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(plt.figure(figsize=(20,10)))\n",
    "plt.plot(np.exp(fold_test_pred[0][0:10]))\n",
    "plt.plot(fold_val_pred[0][0:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testing_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f778d9801d0>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(plt.figure(figsize=(20,10)))\n",
    "plt.plot((fold_test_pred[0][0:10]),'r',label='predicted')\n",
    "plt.plot((validationy[9][0:10]),'b',label='actual')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'revenue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/star/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'revenue'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-81a8af7d1c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'revenue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/star/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/star/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'revenue'"
     ]
    }
   ],
   "source": [
    "test['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train001, y001, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# num_cols = [\"budget\", \"popularity\", \"runtime\"]\n",
    "# cat_cols = [\"original_language\"]\n",
    "# X_train1 = X_train[num_cols]\n",
    "# X_train2 = X_train[cat_cols]\n",
    "\n",
    "# X_test1 = X_test[num_cols]\n",
    "# X_test2 = X_test[cat_cols]\n",
    "\n",
    "\n",
    "# X_train2 = pd.get_dummies(X_train2.original_language)\n",
    "# X_test2 = pd.get_dummies(X_test2.original_language)\n",
    "\n",
    "\n",
    "# scaler1 = StandardScaler()\n",
    "# X_train1 = pd.DataFrame(scaler1.fit_transform(X_train1), columns = list(X_train1))\n",
    "# X_test1 = pd.DataFrame(scaler1.transform(X_test1), columns=list(X_test1))\n",
    "\n",
    "# scaler2 = StandardScaler()\n",
    "# y_train = scaler2.fit_transform(pd.DataFrame(y_train))\n",
    "# y_test = scaler2.transform(pd.DataFrame(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popularity2</th>\n",
       "      <th>rating</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_dayofweek</th>\n",
       "      <th>release_quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>UK Film Council</th>\n",
       "      <th>United Artists</th>\n",
       "      <th>Universal Pictures</th>\n",
       "      <th>Village Roadshow Pictures</th>\n",
       "      <th>Walt Disney Pictures</th>\n",
       "      <th>Warner Bros.</th>\n",
       "      <th>Wild Bunch</th>\n",
       "      <th>Wildwood Enterprises</th>\n",
       "      <th>Working Title Films</th>\n",
       "      <th>production_companies_etc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.454568</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>10.400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.504390</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>15.229</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.009433</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>26.082</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7314.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.997833</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>5.531</td>\n",
       "      <td>7.5</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>13.815512</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>9.829626</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>10.020070</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1915</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9.740321</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1914</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>21.487563</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  popularity  popularity2  rating  totalVotes  release_month  \\\n",
       "0     16.454568    6.575393       10.400     5.0       482.0              2   \n",
       "1     17.504390    8.248895       15.229     6.4      1528.0              8   \n",
       "2     15.009433   64.299990       26.082     8.4      7314.0             10   \n",
       "3     13.997833    3.174936        5.531     7.5       115.0              3   \n",
       "4      0.000000    1.148070        0.000     0.0         0.0              2   \n",
       "...         ...         ...          ...     ...         ...            ...   \n",
       "4996  13.815512    0.680000        0.000     5.0         1.0             16   \n",
       "4997   9.829626    0.600000        0.000     0.0         0.0              7   \n",
       "4998  10.020070    0.600000        0.000     0.0         0.0             15   \n",
       "4999   9.740321    0.600000        0.000     0.0         0.0             15   \n",
       "5000  21.487563    0.600000        0.000     0.0         0.0             14   \n",
       "\n",
       "      release_day  release_year  release_dayofweek  release_quarter  ...  \\\n",
       "0              20          2015                4.0              1.0  ...   \n",
       "1               6          2004                4.0              3.0  ...   \n",
       "2              10          2014                4.0              4.0  ...   \n",
       "3               9          2012                4.0              1.0  ...   \n",
       "4               5          2009                3.0              1.0  ...   \n",
       "...           ...           ...                ...              ...  ...   \n",
       "4996           10          1916                0.0              4.0  ...   \n",
       "4997            5          1916                2.0              3.0  ...   \n",
       "4998           12          1915                2.0              4.0  ...   \n",
       "4999           11          1914                6.0              4.0  ...   \n",
       "5000            4          1914                1.0              2.0  ...   \n",
       "\n",
       "      UK Film Council  United Artists  Universal Pictures  \\\n",
       "0                   0               1                   0   \n",
       "1                   0               0                   0   \n",
       "2                   0               0                   0   \n",
       "3                   0               0                   0   \n",
       "4                   0               0                   0   \n",
       "...               ...             ...                 ...   \n",
       "4996                0               0                   0   \n",
       "4997                0               0                   0   \n",
       "4998                0               0                   0   \n",
       "4999                0               0                   0   \n",
       "5000                0               0                   0   \n",
       "\n",
       "      Village Roadshow Pictures  Walt Disney Pictures  Warner Bros.  \\\n",
       "0                             0                     0             0   \n",
       "1                             0                     1             0   \n",
       "2                             0                     0             0   \n",
       "3                             0                     0             0   \n",
       "4                             0                     0             0   \n",
       "...                         ...                   ...           ...   \n",
       "4996                          0                     0             0   \n",
       "4997                          0                     0             0   \n",
       "4998                          0                     0             0   \n",
       "4999                          0                     0             0   \n",
       "5000                          0                     0             0   \n",
       "\n",
       "      Wild Bunch  Wildwood Enterprises  Working Title Films  \\\n",
       "0              0                     0                    0   \n",
       "1              0                     0                    0   \n",
       "2              0                     0                    0   \n",
       "3              0                     0                    0   \n",
       "4              0                     0                    0   \n",
       "...          ...                   ...                  ...   \n",
       "4996           0                     0                    0   \n",
       "4997           0                     0                    0   \n",
       "4998           0                     0                    0   \n",
       "4999           0                     0                    0   \n",
       "5000           0                     0                    0   \n",
       "\n",
       "      production_companies_etc  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            1  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "4996                         0  \n",
       "4997                         0  \n",
       "4998                         0  \n",
       "4999                         0  \n",
       "5000                         0  \n",
       "\n",
       "[5001 rows x 204 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.32630033, 18.37095922, 16.38751199, ..., 11.53701302,\n",
       "       11.37399668, 13.81551156])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(train, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popularity2</th>\n",
       "      <th>rating</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_dayofweek</th>\n",
       "      <th>release_quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>UK Film Council</th>\n",
       "      <th>United Artists</th>\n",
       "      <th>Universal Pictures</th>\n",
       "      <th>Village Roadshow Pictures</th>\n",
       "      <th>Walt Disney Pictures</th>\n",
       "      <th>Warner Bros.</th>\n",
       "      <th>Wild Bunch</th>\n",
       "      <th>Wildwood Enterprises</th>\n",
       "      <th>Working Title Films</th>\n",
       "      <th>production_companies_etc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912730</td>\n",
       "      <td>1.849</td>\n",
       "      <td>5.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>18.132999</td>\n",
       "      <td>7.970031</td>\n",
       "      <td>10.333</td>\n",
       "      <td>6.1</td>\n",
       "      <td>314.0</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.245682</td>\n",
       "      <td>7.784</td>\n",
       "      <td>5.8</td>\n",
       "      <td>923.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>16.012735</td>\n",
       "      <td>1.808090</td>\n",
       "      <td>3.102</td>\n",
       "      <td>6.2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>1991</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>15.761421</td>\n",
       "      <td>6.904831</td>\n",
       "      <td>9.327</td>\n",
       "      <td>6.8</td>\n",
       "      <td>430.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.605000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>93.0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>16.648724</td>\n",
       "      <td>11.673366</td>\n",
       "      <td>12.202</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1982</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>14.220976</td>\n",
       "      <td>2.776000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>15.201805</td>\n",
       "      <td>7.897000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>360.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>16.993564</td>\n",
       "      <td>4.197544</td>\n",
       "      <td>5.737</td>\n",
       "      <td>5.9</td>\n",
       "      <td>76.0</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3350 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  popularity  popularity2  rating  totalVotes  release_month  \\\n",
       "835    0.000000    0.912730        1.849     5.3        11.0              3   \n",
       "358   18.132999    7.970031       10.333     6.1       314.0             10   \n",
       "138    0.000000   10.245682        7.784     5.8       923.0              2   \n",
       "299   16.012735    1.808090        3.102     6.2        39.0             11   \n",
       "1556  15.761421    6.904831        9.327     6.8       430.0              2   \n",
       "...         ...         ...          ...     ...         ...            ...   \n",
       "4426   0.000000    5.605000        0.000     6.2        93.0             22   \n",
       "466   16.648724   11.673366       12.202     6.7      1662.0              5   \n",
       "3092  14.220976    2.776000        0.000     6.9        10.0             20   \n",
       "3772  15.201805    7.897000        0.000     7.5       360.0             24   \n",
       "860   16.993564    4.197544        5.737     5.9        76.0             11   \n",
       "\n",
       "      release_day  release_year  release_dayofweek  release_quarter  ...  \\\n",
       "835             8          1990                3.0              1.0  ...   \n",
       "358            23          1998                4.0              4.0  ...   \n",
       "138             5          2010                4.0              1.0  ...   \n",
       "299            21          1991                3.0              4.0  ...   \n",
       "1556           21          1996                2.0              1.0  ...   \n",
       "...           ...           ...                ...              ...  ...   \n",
       "4426            7          2004                3.0              3.0  ...   \n",
       "466            28          1982                4.0              2.0  ...   \n",
       "3092            7          2018                4.0              3.0  ...   \n",
       "3772            9          2014                2.0              3.0  ...   \n",
       "860            21          2001                2.0              4.0  ...   \n",
       "\n",
       "      UK Film Council  United Artists  Universal Pictures  \\\n",
       "835                 0               0                   0   \n",
       "358                 0               0                   0   \n",
       "138                 0               0                   0   \n",
       "299                 0               0                   0   \n",
       "1556                0               0                   0   \n",
       "...               ...             ...                 ...   \n",
       "4426                0               0                   0   \n",
       "466                 0               1                   0   \n",
       "3092                0               0                   0   \n",
       "3772                0               0                   0   \n",
       "860                 0               0                   0   \n",
       "\n",
       "      Village Roadshow Pictures  Walt Disney Pictures  Warner Bros.  \\\n",
       "835                           0                     0             0   \n",
       "358                           0                     0             1   \n",
       "138                           0                     0             0   \n",
       "299                           0                     0             0   \n",
       "1556                          0                     0             0   \n",
       "...                         ...                   ...           ...   \n",
       "4426                          0                     0             0   \n",
       "466                           0                     0             0   \n",
       "3092                          0                     0             0   \n",
       "3772                          0                     0             0   \n",
       "860                           0                     0             0   \n",
       "\n",
       "      Wild Bunch  Wildwood Enterprises  Working Title Films  \\\n",
       "835            0                     0                    0   \n",
       "358            0                     0                    0   \n",
       "138            0                     0                    0   \n",
       "299            0                     0                    0   \n",
       "1556           0                     0                    0   \n",
       "...          ...                   ...                  ...   \n",
       "4426           0                     0                    0   \n",
       "466            0                     0                    0   \n",
       "3092           0                     0                    0   \n",
       "3772           0                     0                    0   \n",
       "860            0                     0                    0   \n",
       "\n",
       "      production_companies_etc  \n",
       "835                          1  \n",
       "358                          1  \n",
       "138                          1  \n",
       "299                          1  \n",
       "1556                         1  \n",
       "...                        ...  \n",
       "4426                         0  \n",
       "466                          0  \n",
       "3092                         0  \n",
       "3772                         0  \n",
       "860                          1  \n",
       "\n",
       "[3350 rows x 204 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popularity2</th>\n",
       "      <th>rating</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_dayofweek</th>\n",
       "      <th>release_quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>UK Film Council</th>\n",
       "      <th>United Artists</th>\n",
       "      <th>Universal Pictures</th>\n",
       "      <th>Village Roadshow Pictures</th>\n",
       "      <th>Walt Disney Pictures</th>\n",
       "      <th>Warner Bros.</th>\n",
       "      <th>Wild Bunch</th>\n",
       "      <th>Wildwood Enterprises</th>\n",
       "      <th>Working Title Films</th>\n",
       "      <th>production_companies_etc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>16.705882</td>\n",
       "      <td>7.521346</td>\n",
       "      <td>7.114</td>\n",
       "      <td>7.5</td>\n",
       "      <td>592.0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1989</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.872888</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>15.687313</td>\n",
       "      <td>6.476534</td>\n",
       "      <td>7.223</td>\n",
       "      <td>6.8</td>\n",
       "      <td>210.0</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1987</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.554939</td>\n",
       "      <td>7.127</td>\n",
       "      <td>5.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>13.815512</td>\n",
       "      <td>17.911314</td>\n",
       "      <td>11.206</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1954</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>16.523561</td>\n",
       "      <td>6.777326</td>\n",
       "      <td>9.628</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.837000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.738000</td>\n",
       "      <td>2.454</td>\n",
       "      <td>5.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1983</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>15.071826</td>\n",
       "      <td>0.110065</td>\n",
       "      <td>0.600</td>\n",
       "      <td>6.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780748</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1651 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  popularity  popularity2  rating  totalVotes  release_month  \\\n",
       "1501  16.705882    7.521346        7.114     7.5       592.0             12   \n",
       "2586   0.000000    6.872888        0.000     0.0         0.0              6   \n",
       "2653  15.687313    6.476534        7.223     6.8       210.0              7   \n",
       "1055   0.000000    3.554939        7.127     5.1        86.0              5   \n",
       "705   13.815512   17.911314       11.206     8.3      2675.0              8   \n",
       "...         ...         ...          ...     ...         ...            ...   \n",
       "2114  16.523561    6.777326        9.628     6.0      1054.0              9   \n",
       "3896   0.000000    1.837000        0.000     5.5        11.0             12   \n",
       "1627   0.000000    2.738000        2.454     5.6        36.0              3   \n",
       "2873  15.071826    0.110065        0.600     6.3        31.0              3   \n",
       "1522   0.000000    0.780748        0.000     0.0         0.0              9   \n",
       "\n",
       "      release_day  release_year  release_dayofweek  release_quarter  ...  \\\n",
       "1501           15          1989                4.0              4.0  ...   \n",
       "2586           23          1964                0.0              2.0  ...   \n",
       "2653           24          1987                4.0              3.0  ...   \n",
       "1055            3          2012                3.0              2.0  ...   \n",
       "705             1          1954                5.0              3.0  ...   \n",
       "...           ...           ...                ...              ...  ...   \n",
       "2114           20          2012                3.0              3.0  ...   \n",
       "3896            4          2013                2.0              4.0  ...   \n",
       "1627           18          1983                4.0              1.0  ...   \n",
       "2873           13          2013                2.0              1.0  ...   \n",
       "1522           22          2016                3.0              3.0  ...   \n",
       "\n",
       "      UK Film Council  United Artists  Universal Pictures  \\\n",
       "1501                0               0                   0   \n",
       "2586                0               1                   0   \n",
       "2653                0               0                   0   \n",
       "1055                0               0                   0   \n",
       "705                 0               0                   0   \n",
       "...               ...             ...                 ...   \n",
       "2114                0               0                   0   \n",
       "3896                0               0                   0   \n",
       "1627                0               0                   0   \n",
       "2873                0               0                   0   \n",
       "1522                0               0                   0   \n",
       "\n",
       "      Village Roadshow Pictures  Walt Disney Pictures  Warner Bros.  \\\n",
       "1501                          0                     0             0   \n",
       "2586                          0                     0             0   \n",
       "2653                          0                     0             0   \n",
       "1055                          0                     0             0   \n",
       "705                           0                     0             0   \n",
       "...                         ...                   ...           ...   \n",
       "2114                          0                     0             0   \n",
       "3896                          0                     0             0   \n",
       "1627                          0                     0             1   \n",
       "2873                          0                     0             0   \n",
       "1522                          0                     0             0   \n",
       "\n",
       "      Wild Bunch  Wildwood Enterprises  Working Title Films  \\\n",
       "1501           0                     0                    0   \n",
       "2586           0                     0                    0   \n",
       "2653           0                     0                    0   \n",
       "1055           0                     0                    0   \n",
       "705            0                     0                    0   \n",
       "...          ...                   ...                  ...   \n",
       "2114           0                     0                    0   \n",
       "3896           0                     0                    0   \n",
       "1627           0                     0                    0   \n",
       "2873           0                     0                    0   \n",
       "1522           0                     0                    0   \n",
       "\n",
       "      production_companies_etc  \n",
       "1501                         1  \n",
       "2586                         1  \n",
       "2653                         1  \n",
       "1055                         1  \n",
       "705                          0  \n",
       "...                        ...  \n",
       "2114                         1  \n",
       "3896                         0  \n",
       "1627                         1  \n",
       "2873                         1  \n",
       "1522                         1  \n",
       "\n",
       "[1651 rows x 204 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.08239383, 16.49432994, 14.935839  , ..., 14.93473495,\n",
       "       15.29639257, 16.50896658])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.10497032, 16.33064205, 17.80847587, ..., 17.16189974,\n",
       "       11.66014648, 12.40082084])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-e18bf390ebbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstandardized_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/star/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mscale\u001b[0;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[1;32m    139\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[1;32m    140\u001b[0m                     \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'the scale function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/star/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/star/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# from sklearn import preprocessing\n",
    "# standardized_X = preprocessing.scale(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128)               26240     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 59,521\n",
      "Trainable params: 59,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train1.shape[1], activation='tanh'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='sigmoid'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2680 samples, validate on 670 samples\n",
      "Epoch 1/500\n",
      "2680/2680 [==============================] - 1s 214us/step - loss: 2.9586 - mean_absolute_error: 2.9586 - val_loss: 2.8409 - val_mean_absolute_error: 2.8409\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.84094, saving model to Weights-001--2.84094.hdf5\n",
      "Epoch 2/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8925 - mean_absolute_error: 2.8925 - val_loss: 2.8526 - val_mean_absolute_error: 2.8526\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.84094\n",
      "Epoch 3/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8869 - mean_absolute_error: 2.8869 - val_loss: 2.8661 - val_mean_absolute_error: 2.8661\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.84094\n",
      "Epoch 4/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8869 - mean_absolute_error: 2.8869 - val_loss: 2.8417 - val_mean_absolute_error: 2.8417\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.84094\n",
      "Epoch 5/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8598 - mean_absolute_error: 2.8598 - val_loss: 2.8479 - val_mean_absolute_error: 2.8479\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.84094\n",
      "Epoch 6/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8660 - mean_absolute_error: 2.8660 - val_loss: 2.8409 - val_mean_absolute_error: 2.8409\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.84094 to 2.84087, saving model to Weights-006--2.84087.hdf5\n",
      "Epoch 7/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8624 - mean_absolute_error: 2.8624 - val_loss: 2.8513 - val_mean_absolute_error: 2.8513\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.84087\n",
      "Epoch 8/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8662 - mean_absolute_error: 2.8662 - val_loss: 2.8480 - val_mean_absolute_error: 2.8480\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.84087\n",
      "Epoch 9/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8802 - mean_absolute_error: 2.8802 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.84087 to 2.83723, saving model to Weights-009--2.83723.hdf5\n",
      "Epoch 10/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8636 - mean_absolute_error: 2.8636 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.83723\n",
      "Epoch 11/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8464 - val_mean_absolute_error: 2.8464\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.83723\n",
      "Epoch 12/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8640 - mean_absolute_error: 2.8640 - val_loss: 2.8487 - val_mean_absolute_error: 2.8487\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.83723\n",
      "Epoch 13/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8575 - mean_absolute_error: 2.8575 - val_loss: 2.8416 - val_mean_absolute_error: 2.8416\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.83723\n",
      "Epoch 14/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8635 - mean_absolute_error: 2.8635 - val_loss: 2.8845 - val_mean_absolute_error: 2.8845\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.83723\n",
      "Epoch 15/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8630 - mean_absolute_error: 2.8630 - val_loss: 2.9030 - val_mean_absolute_error: 2.9030\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.83723\n",
      "Epoch 16/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8608 - mean_absolute_error: 2.8608 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.83723\n",
      "Epoch 17/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8596 - mean_absolute_error: 2.8596 - val_loss: 2.8515 - val_mean_absolute_error: 2.8515\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.83723\n",
      "Epoch 18/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8442 - val_mean_absolute_error: 2.8442\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.83723\n",
      "Epoch 19/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.83723\n",
      "Epoch 20/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8561 - mean_absolute_error: 2.8561 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.83723\n",
      "Epoch 21/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8618 - mean_absolute_error: 2.8618 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.83723\n",
      "Epoch 22/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8623 - mean_absolute_error: 2.8623 - val_loss: 2.8416 - val_mean_absolute_error: 2.8416\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.83723\n",
      "Epoch 23/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.83723\n",
      "Epoch 24/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8383 - val_mean_absolute_error: 2.8383\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.83723\n",
      "Epoch 25/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8398 - val_mean_absolute_error: 2.8398\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.83723\n",
      "Epoch 26/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.83723\n",
      "Epoch 27/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8409 - val_mean_absolute_error: 2.8409\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.83723\n",
      "Epoch 28/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8517 - mean_absolute_error: 2.8517 - val_loss: 2.8461 - val_mean_absolute_error: 2.8461\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.83723\n",
      "Epoch 29/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8566 - mean_absolute_error: 2.8566 - val_loss: 2.8451 - val_mean_absolute_error: 2.8451\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.83723\n",
      "Epoch 30/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8607 - mean_absolute_error: 2.8607 - val_loss: 2.8381 - val_mean_absolute_error: 2.8381\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.83723\n",
      "Epoch 31/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8580 - mean_absolute_error: 2.8580 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.83723\n",
      "Epoch 32/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8537 - mean_absolute_error: 2.8537 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.83723\n",
      "Epoch 33/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8584 - mean_absolute_error: 2.8584 - val_loss: 2.8412 - val_mean_absolute_error: 2.8412\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.83723\n",
      "Epoch 34/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8529 - mean_absolute_error: 2.8529 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.83723\n",
      "Epoch 35/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8570 - mean_absolute_error: 2.8570 - val_loss: 2.8622 - val_mean_absolute_error: 2.8622\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.83723\n",
      "Epoch 36/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8599 - mean_absolute_error: 2.8599 - val_loss: 2.8394 - val_mean_absolute_error: 2.8394\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.83723\n",
      "Epoch 37/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.83723\n",
      "Epoch 38/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.83723 to 2.83721, saving model to Weights-038--2.83721.hdf5\n",
      "Epoch 39/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8583 - mean_absolute_error: 2.8583 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.83721 to 2.83719, saving model to Weights-039--2.83719.hdf5\n",
      "Epoch 40/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.83719\n",
      "Epoch 41/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8518 - mean_absolute_error: 2.8518 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.83719\n",
      "Epoch 42/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8446 - val_mean_absolute_error: 2.8446\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.83719\n",
      "Epoch 43/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.83719\n",
      "Epoch 44/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8527 - mean_absolute_error: 2.8527 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.83719\n",
      "Epoch 45/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8406 - val_mean_absolute_error: 2.8406\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.83719\n",
      "Epoch 46/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8538 - val_mean_absolute_error: 2.8538\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.83719\n",
      "Epoch 47/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8566 - mean_absolute_error: 2.8566 - val_loss: 2.8412 - val_mean_absolute_error: 2.8412\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.83719\n",
      "Epoch 48/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8558 - mean_absolute_error: 2.8558 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.83719\n",
      "Epoch 49/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8563 - mean_absolute_error: 2.8563 - val_loss: 2.8417 - val_mean_absolute_error: 2.8417\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.83719\n",
      "Epoch 50/500\n",
      "2680/2680 [==============================] - 0s 91us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8413 - val_mean_absolute_error: 2.8413\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.83719\n",
      "Epoch 51/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8547 - mean_absolute_error: 2.8547 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.83719\n",
      "Epoch 52/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8387 - val_mean_absolute_error: 2.8387\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.83719\n",
      "Epoch 53/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8434 - val_mean_absolute_error: 2.8434\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.83719\n",
      "Epoch 54/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8641 - val_mean_absolute_error: 2.8641\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.83719\n",
      "Epoch 55/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8413 - val_mean_absolute_error: 2.8413\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.83719\n",
      "Epoch 56/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8405 - val_mean_absolute_error: 2.8405\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.83719\n",
      "Epoch 57/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.83719\n",
      "Epoch 58/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8420 - val_mean_absolute_error: 2.8420\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.83719\n",
      "Epoch 59/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8624 - mean_absolute_error: 2.8624 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.83719\n",
      "Epoch 60/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8604 - mean_absolute_error: 2.8604 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.83719\n",
      "Epoch 61/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8577 - mean_absolute_error: 2.8577 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.83719\n",
      "Epoch 62/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8514 - val_mean_absolute_error: 2.8514\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.83719\n",
      "Epoch 63/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8554 - mean_absolute_error: 2.8554 - val_loss: 2.8426 - val_mean_absolute_error: 2.8426\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.83719\n",
      "Epoch 64/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8585 - mean_absolute_error: 2.8585 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.83719\n",
      "Epoch 65/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.83719\n",
      "Epoch 66/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8509 - mean_absolute_error: 2.8509 - val_loss: 2.8821 - val_mean_absolute_error: 2.8821\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.83719\n",
      "Epoch 67/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.83719\n",
      "Epoch 68/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8601 - mean_absolute_error: 2.8601 - val_loss: 2.8445 - val_mean_absolute_error: 2.8445\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.83719\n",
      "Epoch 69/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8625 - mean_absolute_error: 2.8625 - val_loss: 2.8411 - val_mean_absolute_error: 2.8411\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.83719\n",
      "Epoch 70/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8489 - val_mean_absolute_error: 2.8489\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.83719\n",
      "Epoch 71/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8561 - mean_absolute_error: 2.8561 - val_loss: 2.8385 - val_mean_absolute_error: 2.8385\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.83719\n",
      "Epoch 72/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.83719\n",
      "Epoch 73/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8501 - val_mean_absolute_error: 2.8501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00073: val_loss did not improve from 2.83719\n",
      "Epoch 74/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8526 - mean_absolute_error: 2.8526 - val_loss: 2.8433 - val_mean_absolute_error: 2.8433\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.83719\n",
      "Epoch 75/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8514 - mean_absolute_error: 2.8514 - val_loss: 2.8386 - val_mean_absolute_error: 2.8386\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.83719\n",
      "Epoch 76/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8525 - val_mean_absolute_error: 2.8525\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.83719\n",
      "Epoch 77/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8594 - mean_absolute_error: 2.8594 - val_loss: 2.8485 - val_mean_absolute_error: 2.8485\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.83719\n",
      "Epoch 78/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8513 - val_mean_absolute_error: 2.8513\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.83719\n",
      "Epoch 79/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8542 - mean_absolute_error: 2.8542 - val_loss: 2.8426 - val_mean_absolute_error: 2.8426\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.83719\n",
      "Epoch 80/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8554 - mean_absolute_error: 2.8554 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.83719\n",
      "Epoch 81/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8575 - mean_absolute_error: 2.8575 - val_loss: 2.8391 - val_mean_absolute_error: 2.8391\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.83719\n",
      "Epoch 82/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8542 - mean_absolute_error: 2.8542 - val_loss: 2.8385 - val_mean_absolute_error: 2.8385\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.83719\n",
      "Epoch 83/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.83719\n",
      "Epoch 84/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8503 - val_mean_absolute_error: 2.8503\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.83719\n",
      "Epoch 85/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.83719\n",
      "Epoch 86/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8532 - mean_absolute_error: 2.8532 - val_loss: 2.8527 - val_mean_absolute_error: 2.8527\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.83719\n",
      "Epoch 87/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8404 - val_mean_absolute_error: 2.8404\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.83719\n",
      "Epoch 88/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8569 - mean_absolute_error: 2.8569 - val_loss: 2.8381 - val_mean_absolute_error: 2.8381\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.83719\n",
      "Epoch 89/500\n",
      "2680/2680 [==============================] - 0s 102us/step - loss: 2.8554 - mean_absolute_error: 2.8554 - val_loss: 2.8497 - val_mean_absolute_error: 2.8497\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.83719\n",
      "Epoch 90/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8529 - mean_absolute_error: 2.8529 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00090: val_loss improved from 2.83719 to 2.83718, saving model to Weights-090--2.83718.hdf5\n",
      "Epoch 91/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8617 - mean_absolute_error: 2.8617 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.83718\n",
      "Epoch 92/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8408 - val_mean_absolute_error: 2.8408\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.83718\n",
      "Epoch 93/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8564 - mean_absolute_error: 2.8564 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.83718\n",
      "Epoch 94/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.83718\n",
      "Epoch 95/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8522 - mean_absolute_error: 2.8522 - val_loss: 2.8433 - val_mean_absolute_error: 2.8433\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.83718\n",
      "Epoch 96/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8418 - val_mean_absolute_error: 2.8418\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.83718\n",
      "Epoch 97/500\n",
      "2680/2680 [==============================] - 0s 91us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.83718\n",
      "Epoch 98/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8588 - mean_absolute_error: 2.8588 - val_loss: 2.8446 - val_mean_absolute_error: 2.8446\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.83718\n",
      "Epoch 99/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8399 - val_mean_absolute_error: 2.8399\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.83718\n",
      "Epoch 100/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8417 - val_mean_absolute_error: 2.8417\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.83718\n",
      "Epoch 101/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8475 - val_mean_absolute_error: 2.8475\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2.83718\n",
      "Epoch 102/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8602 - mean_absolute_error: 2.8602 - val_loss: 2.8670 - val_mean_absolute_error: 2.8670\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2.83718\n",
      "Epoch 103/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2.83718\n",
      "Epoch 104/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8629 - mean_absolute_error: 2.8629 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2.83718\n",
      "Epoch 105/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8537 - mean_absolute_error: 2.8537 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2.83718\n",
      "Epoch 106/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8495 - val_mean_absolute_error: 2.8495\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2.83718\n",
      "Epoch 107/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.83718\n",
      "Epoch 108/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8545 - mean_absolute_error: 2.8545 - val_loss: 2.8433 - val_mean_absolute_error: 2.8433\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2.83718\n",
      "Epoch 109/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8519 - mean_absolute_error: 2.8519 - val_loss: 2.8402 - val_mean_absolute_error: 2.8402\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2.83718\n",
      "Epoch 110/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8640 - mean_absolute_error: 2.8640 - val_loss: 2.8535 - val_mean_absolute_error: 2.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00110: val_loss did not improve from 2.83718\n",
      "Epoch 111/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8536 - mean_absolute_error: 2.8536 - val_loss: 2.8401 - val_mean_absolute_error: 2.8401\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2.83718\n",
      "Epoch 112/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8470 - mean_absolute_error: 2.8470 - val_loss: 2.8609 - val_mean_absolute_error: 2.8609\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2.83718\n",
      "Epoch 113/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8430 - val_mean_absolute_error: 2.8430\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2.83718\n",
      "Epoch 114/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8474 - mean_absolute_error: 2.8474 - val_loss: 2.8393 - val_mean_absolute_error: 2.8393\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2.83718\n",
      "Epoch 115/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8394 - val_mean_absolute_error: 2.8394\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2.83718\n",
      "Epoch 116/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2.83718\n",
      "Epoch 117/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8609 - mean_absolute_error: 2.8609 - val_loss: 2.8471 - val_mean_absolute_error: 2.8471\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2.83718\n",
      "Epoch 118/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2.83718\n",
      "Epoch 119/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8531 - mean_absolute_error: 2.8531 - val_loss: 2.8518 - val_mean_absolute_error: 2.8518\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2.83718\n",
      "Epoch 120/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8417 - val_mean_absolute_error: 2.8417\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2.83718\n",
      "Epoch 121/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8528 - mean_absolute_error: 2.8528 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2.83718\n",
      "Epoch 122/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8450 - val_mean_absolute_error: 2.8450\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 2.83718\n",
      "Epoch 123/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8503 - mean_absolute_error: 2.8503 - val_loss: 2.8583 - val_mean_absolute_error: 2.8583\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2.83718\n",
      "Epoch 124/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8605 - mean_absolute_error: 2.8605 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 2.83718\n",
      "Epoch 125/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8638 - mean_absolute_error: 2.8638 - val_loss: 2.8430 - val_mean_absolute_error: 2.8430\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 2.83718\n",
      "Epoch 126/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8517 - mean_absolute_error: 2.8517 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2.83718\n",
      "Epoch 127/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8512 - mean_absolute_error: 2.8512 - val_loss: 2.8549 - val_mean_absolute_error: 2.8549\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 2.83718\n",
      "Epoch 128/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8594 - mean_absolute_error: 2.8594 - val_loss: 2.8389 - val_mean_absolute_error: 2.8389\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 2.83718\n",
      "Epoch 129/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 2.83718\n",
      "Epoch 130/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8557 - mean_absolute_error: 2.8557 - val_loss: 2.8381 - val_mean_absolute_error: 2.8381\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 2.83718\n",
      "Epoch 131/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 2.83718\n",
      "Epoch 132/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8520 - mean_absolute_error: 2.8520 - val_loss: 2.8524 - val_mean_absolute_error: 2.8524\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2.83718\n",
      "Epoch 133/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8633 - mean_absolute_error: 2.8633 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 2.83718\n",
      "Epoch 134/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8585 - mean_absolute_error: 2.8585 - val_loss: 2.8401 - val_mean_absolute_error: 2.8401\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 2.83718\n",
      "Epoch 135/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8532 - mean_absolute_error: 2.8532 - val_loss: 2.8504 - val_mean_absolute_error: 2.8504\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2.83718\n",
      "Epoch 136/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8586 - mean_absolute_error: 2.8586 - val_loss: 2.8474 - val_mean_absolute_error: 2.8474\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2.83718\n",
      "Epoch 137/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8562 - mean_absolute_error: 2.8562 - val_loss: 2.8485 - val_mean_absolute_error: 2.8485\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2.83718\n",
      "Epoch 138/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8584 - mean_absolute_error: 2.8584 - val_loss: 2.8503 - val_mean_absolute_error: 2.8503\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 2.83718\n",
      "Epoch 139/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8452 - val_mean_absolute_error: 2.8452\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 2.83718\n",
      "Epoch 140/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8425 - val_mean_absolute_error: 2.8425\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 2.83718\n",
      "Epoch 141/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8385 - val_mean_absolute_error: 2.8385\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 2.83718\n",
      "Epoch 142/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8470 - mean_absolute_error: 2.8470 - val_loss: 2.8645 - val_mean_absolute_error: 2.8645\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 2.83718\n",
      "Epoch 143/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 2.83718\n",
      "Epoch 144/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8609 - mean_absolute_error: 2.8609 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 2.83718\n",
      "Epoch 145/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8529 - mean_absolute_error: 2.8529 - val_loss: 2.8469 - val_mean_absolute_error: 2.8469\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 2.83718\n",
      "Epoch 146/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8520 - mean_absolute_error: 2.8520 - val_loss: 2.8420 - val_mean_absolute_error: 2.8420\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2.83718\n",
      "Epoch 147/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8582 - mean_absolute_error: 2.8582 - val_loss: 2.8418 - val_mean_absolute_error: 2.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00147: val_loss did not improve from 2.83718\n",
      "Epoch 148/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8530 - mean_absolute_error: 2.8530 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2.83718\n",
      "Epoch 149/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8402 - val_mean_absolute_error: 2.8402\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2.83718\n",
      "Epoch 150/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8573 - mean_absolute_error: 2.8573 - val_loss: 2.8408 - val_mean_absolute_error: 2.8408\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 2.83718\n",
      "Epoch 151/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8631 - mean_absolute_error: 2.8631 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 2.83718\n",
      "Epoch 152/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8408 - val_mean_absolute_error: 2.8408\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 2.83718\n",
      "Epoch 153/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8601 - val_mean_absolute_error: 2.8601\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 2.83718\n",
      "Epoch 154/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8454 - val_mean_absolute_error: 2.8454\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 2.83718\n",
      "Epoch 155/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8586 - mean_absolute_error: 2.8586 - val_loss: 2.8442 - val_mean_absolute_error: 2.8442\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 2.83718\n",
      "Epoch 156/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8572 - mean_absolute_error: 2.8572 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 2.83718\n",
      "Epoch 157/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8521 - mean_absolute_error: 2.8521 - val_loss: 2.8483 - val_mean_absolute_error: 2.8483\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 2.83718\n",
      "Epoch 158/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8536 - mean_absolute_error: 2.8536 - val_loss: 2.8445 - val_mean_absolute_error: 2.8445\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 2.83718\n",
      "Epoch 159/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8528 - mean_absolute_error: 2.8528 - val_loss: 2.8437 - val_mean_absolute_error: 2.8437\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 2.83718\n",
      "Epoch 160/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8523 - mean_absolute_error: 2.8523 - val_loss: 2.8415 - val_mean_absolute_error: 2.8415\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 2.83718\n",
      "Epoch 161/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8534 - mean_absolute_error: 2.8534 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 2.83718\n",
      "Epoch 162/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8399 - val_mean_absolute_error: 2.8399\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 2.83718\n",
      "Epoch 163/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8582 - mean_absolute_error: 2.8582 - val_loss: 2.8492 - val_mean_absolute_error: 2.8492\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 2.83718\n",
      "Epoch 164/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8580 - mean_absolute_error: 2.8580 - val_loss: 2.8416 - val_mean_absolute_error: 2.8416\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 2.83718\n",
      "Epoch 165/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 2.83718\n",
      "Epoch 166/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8667 - mean_absolute_error: 2.8667 - val_loss: 2.8465 - val_mean_absolute_error: 2.8465\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 2.83718\n",
      "Epoch 167/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8602 - mean_absolute_error: 2.8602 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 2.83718\n",
      "Epoch 168/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8569 - mean_absolute_error: 2.8569 - val_loss: 2.8400 - val_mean_absolute_error: 2.8400\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 2.83718\n",
      "Epoch 169/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8405 - val_mean_absolute_error: 2.8405\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 2.83718\n",
      "Epoch 170/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8467 - val_mean_absolute_error: 2.8467\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 2.83718\n",
      "Epoch 171/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8610 - mean_absolute_error: 2.8610 - val_loss: 2.8555 - val_mean_absolute_error: 2.8555\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 2.83718\n",
      "Epoch 172/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8482 - val_mean_absolute_error: 2.8482\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 2.83718\n",
      "Epoch 173/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 2.83718\n",
      "Epoch 174/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8616 - mean_absolute_error: 2.8616 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 2.83718\n",
      "Epoch 175/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8647 - val_mean_absolute_error: 2.8647\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 2.83718\n",
      "Epoch 176/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8562 - mean_absolute_error: 2.8562 - val_loss: 2.8519 - val_mean_absolute_error: 2.8519\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 2.83718\n",
      "Epoch 177/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8523 - mean_absolute_error: 2.8523 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 2.83718\n",
      "Epoch 178/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8685 - val_mean_absolute_error: 2.8685\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 2.83718\n",
      "Epoch 179/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8590 - mean_absolute_error: 2.8590 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 2.83718\n",
      "Epoch 180/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8535 - mean_absolute_error: 2.8535 - val_loss: 2.8520 - val_mean_absolute_error: 2.8520\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 2.83718\n",
      "Epoch 181/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8603 - mean_absolute_error: 2.8603 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 2.83718\n",
      "Epoch 182/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8405 - val_mean_absolute_error: 2.8405\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 2.83718\n",
      "Epoch 183/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8584 - mean_absolute_error: 2.8584 - val_loss: 2.8521 - val_mean_absolute_error: 2.8521\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 2.83718\n",
      "Epoch 184/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8614 - mean_absolute_error: 2.8614 - val_loss: 2.8569 - val_mean_absolute_error: 2.8569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00184: val_loss did not improve from 2.83718\n",
      "Epoch 185/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 2.83718\n",
      "Epoch 186/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8522 - mean_absolute_error: 2.8522 - val_loss: 2.8537 - val_mean_absolute_error: 2.8537\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 2.83718\n",
      "Epoch 187/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8570 - mean_absolute_error: 2.8570 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 2.83718\n",
      "Epoch 188/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8386 - val_mean_absolute_error: 2.8386\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 2.83718\n",
      "Epoch 189/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8516 - val_mean_absolute_error: 2.8516\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 2.83718\n",
      "Epoch 190/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8438 - val_mean_absolute_error: 2.8438\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 2.83718\n",
      "Epoch 191/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8530 - val_mean_absolute_error: 2.8530\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 2.83718\n",
      "Epoch 192/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 2.83718\n",
      "Epoch 193/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8608 - mean_absolute_error: 2.8608 - val_loss: 2.8387 - val_mean_absolute_error: 2.8387\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 2.83718\n",
      "Epoch 194/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8567 - mean_absolute_error: 2.8567 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 2.83718\n",
      "Epoch 195/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8397 - val_mean_absolute_error: 2.8397\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 2.83718\n",
      "Epoch 196/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8572 - mean_absolute_error: 2.8572 - val_loss: 2.8483 - val_mean_absolute_error: 2.8483\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 2.83718\n",
      "Epoch 197/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8477 - val_mean_absolute_error: 2.8477\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 2.83718\n",
      "Epoch 198/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8621 - mean_absolute_error: 2.8621 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 2.83718\n",
      "Epoch 199/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8558 - mean_absolute_error: 2.8558 - val_loss: 2.8446 - val_mean_absolute_error: 2.8446\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 2.83718\n",
      "Epoch 200/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8523 - mean_absolute_error: 2.8523 - val_loss: 2.8506 - val_mean_absolute_error: 2.8506\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 2.83718\n",
      "Epoch 201/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8560 - mean_absolute_error: 2.8560 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 2.83718\n",
      "Epoch 202/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8573 - mean_absolute_error: 2.8573 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 2.83718\n",
      "Epoch 203/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 2.83718\n",
      "Epoch 204/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8411 - val_mean_absolute_error: 2.8411\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 2.83718\n",
      "Epoch 205/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8533 - mean_absolute_error: 2.8533 - val_loss: 2.8874 - val_mean_absolute_error: 2.8874\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 2.83718\n",
      "Epoch 206/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8627 - mean_absolute_error: 2.8627 - val_loss: 2.8510 - val_mean_absolute_error: 2.8510\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 2.83718\n",
      "Epoch 207/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8561 - mean_absolute_error: 2.8561 - val_loss: 2.8401 - val_mean_absolute_error: 2.8401\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 2.83718\n",
      "Epoch 208/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8638 - mean_absolute_error: 2.8638 - val_loss: 2.8407 - val_mean_absolute_error: 2.8407\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 2.83718\n",
      "Epoch 209/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 2.83718\n",
      "Epoch 210/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8536 - mean_absolute_error: 2.8536 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 2.83718\n",
      "Epoch 211/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8566 - mean_absolute_error: 2.8566 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 2.83718\n",
      "Epoch 212/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 2.83718\n",
      "Epoch 213/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 2.83718\n",
      "Epoch 214/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8560 - mean_absolute_error: 2.8560 - val_loss: 2.8483 - val_mean_absolute_error: 2.8483\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 2.83718\n",
      "Epoch 215/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8517 - val_mean_absolute_error: 2.8517\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 2.83718\n",
      "Epoch 216/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8536 - mean_absolute_error: 2.8536 - val_loss: 2.8409 - val_mean_absolute_error: 2.8409\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 2.83718\n",
      "Epoch 217/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8531 - mean_absolute_error: 2.8531 - val_loss: 2.8393 - val_mean_absolute_error: 2.8393\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 2.83718\n",
      "Epoch 218/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8558 - mean_absolute_error: 2.8558 - val_loss: 2.8403 - val_mean_absolute_error: 2.8403\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 2.83718\n",
      "Epoch 219/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8408 - val_mean_absolute_error: 2.8408\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 2.83718\n",
      "Epoch 220/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8404 - val_mean_absolute_error: 2.8404\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 2.83718\n",
      "Epoch 221/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8594 - mean_absolute_error: 2.8594 - val_loss: 2.8616 - val_mean_absolute_error: 2.8616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00221: val_loss did not improve from 2.83718\n",
      "Epoch 222/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8600 - mean_absolute_error: 2.8600 - val_loss: 2.8430 - val_mean_absolute_error: 2.8430\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 2.83718\n",
      "Epoch 223/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8535 - val_mean_absolute_error: 2.8535\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 2.83718\n",
      "Epoch 224/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8588 - mean_absolute_error: 2.8588 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 2.83718\n",
      "Epoch 225/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8605 - mean_absolute_error: 2.8605 - val_loss: 2.8421 - val_mean_absolute_error: 2.8421\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 2.83718\n",
      "Epoch 226/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8599 - mean_absolute_error: 2.8599 - val_loss: 2.8479 - val_mean_absolute_error: 2.8479\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 2.83718\n",
      "Epoch 227/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8527 - val_mean_absolute_error: 2.8527\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 2.83718\n",
      "Epoch 228/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8416 - val_mean_absolute_error: 2.8416\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 2.83718\n",
      "Epoch 229/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8448 - val_mean_absolute_error: 2.8448\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 2.83718\n",
      "Epoch 230/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8619 - mean_absolute_error: 2.8619 - val_loss: 2.8405 - val_mean_absolute_error: 2.8405\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 2.83718\n",
      "Epoch 231/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 2.83718\n",
      "Epoch 232/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8490 - val_mean_absolute_error: 2.8490\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 2.83718\n",
      "Epoch 233/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8422 - val_mean_absolute_error: 2.8422\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 2.83718\n",
      "Epoch 234/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8595 - mean_absolute_error: 2.8595 - val_loss: 2.8409 - val_mean_absolute_error: 2.8409\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 2.83718\n",
      "Epoch 235/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8594 - mean_absolute_error: 2.8594 - val_loss: 2.8410 - val_mean_absolute_error: 2.8410\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 2.83718\n",
      "Epoch 236/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8619 - mean_absolute_error: 2.8619 - val_loss: 2.8576 - val_mean_absolute_error: 2.8576\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 2.83718\n",
      "Epoch 237/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8628 - mean_absolute_error: 2.8628 - val_loss: 2.8414 - val_mean_absolute_error: 2.8414\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 2.83718\n",
      "Epoch 238/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 2.83718\n",
      "Epoch 239/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 2.83718\n",
      "Epoch 240/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8471 - val_mean_absolute_error: 2.8471\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 2.83718\n",
      "Epoch 241/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8589 - mean_absolute_error: 2.8589 - val_loss: 2.8594 - val_mean_absolute_error: 2.8594\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 2.83718\n",
      "Epoch 242/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 2.83718\n",
      "Epoch 243/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00243: val_loss improved from 2.83718 to 2.83718, saving model to Weights-243--2.83718.hdf5\n",
      "Epoch 244/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8533 - mean_absolute_error: 2.8533 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 2.83718\n",
      "Epoch 245/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8517 - mean_absolute_error: 2.8517 - val_loss: 2.8444 - val_mean_absolute_error: 2.8444\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 2.83718\n",
      "Epoch 246/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8534 - mean_absolute_error: 2.8534 - val_loss: 2.8419 - val_mean_absolute_error: 2.8419\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 2.83718\n",
      "Epoch 247/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8633 - mean_absolute_error: 2.8633 - val_loss: 2.8408 - val_mean_absolute_error: 2.8408\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 2.83718\n",
      "Epoch 248/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8522 - mean_absolute_error: 2.8522 - val_loss: 2.8652 - val_mean_absolute_error: 2.8652\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 2.83718\n",
      "Epoch 249/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8709 - mean_absolute_error: 2.8709 - val_loss: 2.8460 - val_mean_absolute_error: 2.8460\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 2.83718\n",
      "Epoch 250/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8496 - mean_absolute_error: 2.8496 - val_loss: 2.8531 - val_mean_absolute_error: 2.8531\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 2.83718\n",
      "Epoch 251/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8431 - val_mean_absolute_error: 2.8431\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 2.83718\n",
      "Epoch 252/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 2.83718\n",
      "Epoch 253/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8430 - val_mean_absolute_error: 2.8430\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 2.83718\n",
      "Epoch 254/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8394 - val_mean_absolute_error: 2.8394\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 2.83718\n",
      "Epoch 255/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8547 - mean_absolute_error: 2.8547 - val_loss: 2.8502 - val_mean_absolute_error: 2.8502\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 2.83718\n",
      "Epoch 256/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8642 - mean_absolute_error: 2.8642 - val_loss: 2.8495 - val_mean_absolute_error: 2.8495\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 2.83718\n",
      "Epoch 257/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8479 - mean_absolute_error: 2.8479 - val_loss: 2.8579 - val_mean_absolute_error: 2.8579\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 2.83718\n",
      "Epoch 258/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8651 - val_mean_absolute_error: 2.8651\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 2.83718\n",
      "Epoch 259/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8592 - mean_absolute_error: 2.8592 - val_loss: 2.8439 - val_mean_absolute_error: 2.8439\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 2.83718\n",
      "Epoch 260/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8577 - mean_absolute_error: 2.8577 - val_loss: 2.8390 - val_mean_absolute_error: 2.8390\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 2.83718\n",
      "Epoch 261/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8636 - mean_absolute_error: 2.8636 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 2.83718\n",
      "Epoch 262/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8543 - val_mean_absolute_error: 2.8543\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 2.83718\n",
      "Epoch 263/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8686 - mean_absolute_error: 2.8686 - val_loss: 2.8485 - val_mean_absolute_error: 2.8485\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 2.83718\n",
      "Epoch 264/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8504 - val_mean_absolute_error: 2.8504\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 2.83718\n",
      "Epoch 265/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8500 - val_mean_absolute_error: 2.8500\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 2.83718\n",
      "Epoch 266/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8540 - mean_absolute_error: 2.8540 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 2.83718\n",
      "Epoch 267/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8562 - mean_absolute_error: 2.8562 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 2.83718\n",
      "Epoch 268/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8575 - mean_absolute_error: 2.8575 - val_loss: 2.8445 - val_mean_absolute_error: 2.8445\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 2.83718\n",
      "Epoch 269/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 2.83718\n",
      "Epoch 270/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 2.83718\n",
      "Epoch 271/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8633 - mean_absolute_error: 2.8633 - val_loss: 2.8443 - val_mean_absolute_error: 2.8443\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 2.83718\n",
      "Epoch 272/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8508 - val_mean_absolute_error: 2.8508\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 2.83718\n",
      "Epoch 273/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8421 - val_mean_absolute_error: 2.8421\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 2.83718\n",
      "Epoch 274/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8595 - mean_absolute_error: 2.8595 - val_loss: 2.8808 - val_mean_absolute_error: 2.8808\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 2.83718\n",
      "Epoch 275/500\n",
      "2680/2680 [==============================] - 0s 101us/step - loss: 2.8616 - mean_absolute_error: 2.8616 - val_loss: 2.8514 - val_mean_absolute_error: 2.8514\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 2.83718\n",
      "Epoch 276/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8419 - val_mean_absolute_error: 2.8419\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 2.83718\n",
      "Epoch 277/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8545 - mean_absolute_error: 2.8545 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 2.83718\n",
      "Epoch 278/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8614 - mean_absolute_error: 2.8614 - val_loss: 2.8545 - val_mean_absolute_error: 2.8545\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 2.83718\n",
      "Epoch 279/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 2.83718\n",
      "Epoch 280/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 2.83718\n",
      "Epoch 281/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8527 - mean_absolute_error: 2.8527 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 2.83718\n",
      "Epoch 282/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8581 - mean_absolute_error: 2.8581 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 2.83718\n",
      "Epoch 283/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8591 - mean_absolute_error: 2.8591 - val_loss: 2.8394 - val_mean_absolute_error: 2.8394\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 2.83718\n",
      "Epoch 284/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8434 - val_mean_absolute_error: 2.8434\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 2.83718\n",
      "Epoch 285/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8628 - mean_absolute_error: 2.8628 - val_loss: 2.8431 - val_mean_absolute_error: 2.8431\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 2.83718\n",
      "Epoch 286/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8448 - val_mean_absolute_error: 2.8448\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 2.83718\n",
      "Epoch 287/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8547 - mean_absolute_error: 2.8547 - val_loss: 2.8461 - val_mean_absolute_error: 2.8461\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 2.83718\n",
      "Epoch 288/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 2.83718\n",
      "Epoch 289/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8530 - mean_absolute_error: 2.8530 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 2.83718\n",
      "Epoch 290/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8484 - val_mean_absolute_error: 2.8484\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 2.83718\n",
      "Epoch 291/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8557 - mean_absolute_error: 2.8557 - val_loss: 2.8380 - val_mean_absolute_error: 2.8380\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 2.83718\n",
      "Epoch 292/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8562 - mean_absolute_error: 2.8562 - val_loss: 2.8439 - val_mean_absolute_error: 2.8439\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 2.83718\n",
      "Epoch 293/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8562 - mean_absolute_error: 2.8562 - val_loss: 2.8505 - val_mean_absolute_error: 2.8505\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 2.83718\n",
      "Epoch 294/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8558 - mean_absolute_error: 2.8558 - val_loss: 2.8396 - val_mean_absolute_error: 2.8396\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 2.83718\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 2.83718\n",
      "Epoch 296/500\n",
      "2680/2680 [==============================] - 0s 101us/step - loss: 2.8601 - mean_absolute_error: 2.8601 - val_loss: 2.8473 - val_mean_absolute_error: 2.8473\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 2.83718\n",
      "Epoch 297/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8633 - mean_absolute_error: 2.8633 - val_loss: 2.8443 - val_mean_absolute_error: 2.8443\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 2.83718\n",
      "Epoch 298/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8518 - mean_absolute_error: 2.8518 - val_loss: 2.8617 - val_mean_absolute_error: 2.8617\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 2.83718\n",
      "Epoch 299/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8629 - mean_absolute_error: 2.8629 - val_loss: 2.8460 - val_mean_absolute_error: 2.8460\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 2.83718\n",
      "Epoch 300/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8395 - val_mean_absolute_error: 2.8395\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 2.83718\n",
      "Epoch 301/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8563 - mean_absolute_error: 2.8563 - val_loss: 2.8395 - val_mean_absolute_error: 2.8395\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 2.83718\n",
      "Epoch 302/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 2.83718\n",
      "Epoch 303/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8517 - mean_absolute_error: 2.8517 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 2.83718\n",
      "Epoch 304/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8618 - val_mean_absolute_error: 2.8618\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 2.83718\n",
      "Epoch 305/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8590 - mean_absolute_error: 2.8590 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 2.83718\n",
      "Epoch 306/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8535 - mean_absolute_error: 2.8535 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 2.83718\n",
      "Epoch 307/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 2.83718\n",
      "Epoch 308/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8414 - val_mean_absolute_error: 2.8414\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 2.83718\n",
      "Epoch 309/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8509 - mean_absolute_error: 2.8509 - val_loss: 2.8765 - val_mean_absolute_error: 2.8765\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 2.83718\n",
      "Epoch 310/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8564 - mean_absolute_error: 2.8564 - val_loss: 2.8452 - val_mean_absolute_error: 2.8452\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 2.83718\n",
      "Epoch 311/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8599 - mean_absolute_error: 2.8599 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 2.83718\n",
      "Epoch 312/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8545 - mean_absolute_error: 2.8545 - val_loss: 2.8461 - val_mean_absolute_error: 2.8461\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 2.83718\n",
      "Epoch 313/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8540 - mean_absolute_error: 2.8540 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 2.83718\n",
      "Epoch 314/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8604 - mean_absolute_error: 2.8604 - val_loss: 2.8437 - val_mean_absolute_error: 2.8437\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 2.83718\n",
      "Epoch 315/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8520 - mean_absolute_error: 2.8520 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 2.83718\n",
      "Epoch 316/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8521 - mean_absolute_error: 2.8521 - val_loss: 2.8495 - val_mean_absolute_error: 2.8495\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 2.83718\n",
      "Epoch 317/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 2.83718\n",
      "Epoch 318/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8508 - val_mean_absolute_error: 2.8508\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 2.83718\n",
      "Epoch 319/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 2.83718\n",
      "Epoch 320/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8644 - mean_absolute_error: 2.8644 - val_loss: 2.8413 - val_mean_absolute_error: 2.8413\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 2.83718\n",
      "Epoch 321/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8581 - mean_absolute_error: 2.8581 - val_loss: 2.8420 - val_mean_absolute_error: 2.8420\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 2.83718\n",
      "Epoch 322/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8582 - mean_absolute_error: 2.8582 - val_loss: 2.8578 - val_mean_absolute_error: 2.8578\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 2.83718\n",
      "Epoch 323/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8547 - mean_absolute_error: 2.8547 - val_loss: 2.8478 - val_mean_absolute_error: 2.8478\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 2.83718\n",
      "Epoch 324/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8608 - mean_absolute_error: 2.8608 - val_loss: 2.8581 - val_mean_absolute_error: 2.8581\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 2.83718\n",
      "Epoch 325/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8585 - mean_absolute_error: 2.8585 - val_loss: 2.8390 - val_mean_absolute_error: 2.8390\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 2.83718\n",
      "Epoch 326/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8436 - val_mean_absolute_error: 2.8436\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 2.83718\n",
      "Epoch 327/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8536 - mean_absolute_error: 2.8536 - val_loss: 2.8395 - val_mean_absolute_error: 2.8395\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 2.83718\n",
      "Epoch 328/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8520 - mean_absolute_error: 2.8520 - val_loss: 2.8410 - val_mean_absolute_error: 2.8410\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 2.83718\n",
      "Epoch 329/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 2.83718\n",
      "Epoch 330/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8530 - mean_absolute_error: 2.8530 - val_loss: 2.8398 - val_mean_absolute_error: 2.8398\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 2.83718\n",
      "Epoch 331/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8541 - mean_absolute_error: 2.8541 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 2.83718\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8534 - mean_absolute_error: 2.8534 - val_loss: 2.8401 - val_mean_absolute_error: 2.8401\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 2.83718\n",
      "Epoch 333/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8512 - mean_absolute_error: 2.8512 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 2.83718\n",
      "Epoch 334/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8582 - mean_absolute_error: 2.8582 - val_loss: 2.8399 - val_mean_absolute_error: 2.8399\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 2.83718\n",
      "Epoch 335/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8617 - mean_absolute_error: 2.8617 - val_loss: 2.8407 - val_mean_absolute_error: 2.8407\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 2.83718\n",
      "Epoch 336/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8590 - mean_absolute_error: 2.8590 - val_loss: 2.8604 - val_mean_absolute_error: 2.8604\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 2.83718\n",
      "Epoch 337/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 2.83718\n",
      "Epoch 338/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8452 - val_mean_absolute_error: 2.8452\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 2.83718\n",
      "Epoch 339/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8582 - mean_absolute_error: 2.8582 - val_loss: 2.8894 - val_mean_absolute_error: 2.8894\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 2.83718\n",
      "Epoch 340/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8502 - mean_absolute_error: 2.8502 - val_loss: 2.8431 - val_mean_absolute_error: 2.8431\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 2.83718\n",
      "Epoch 341/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8534 - mean_absolute_error: 2.8534 - val_loss: 2.8453 - val_mean_absolute_error: 2.8453\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 2.83718\n",
      "Epoch 342/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8405 - val_mean_absolute_error: 2.8405\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 2.83718\n",
      "Epoch 343/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8599 - mean_absolute_error: 2.8599 - val_loss: 2.8483 - val_mean_absolute_error: 2.8483\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 2.83718\n",
      "Epoch 344/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8397 - val_mean_absolute_error: 2.8397\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 2.83718\n",
      "Epoch 345/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8594 - mean_absolute_error: 2.8594 - val_loss: 2.8467 - val_mean_absolute_error: 2.8467\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 2.83718\n",
      "Epoch 346/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8537 - mean_absolute_error: 2.8537 - val_loss: 2.8451 - val_mean_absolute_error: 2.8451\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 2.83718\n",
      "Epoch 347/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8599 - mean_absolute_error: 2.8599 - val_loss: 2.8524 - val_mean_absolute_error: 2.8524\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 2.83718\n",
      "Epoch 348/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8597 - mean_absolute_error: 2.8597 - val_loss: 2.8406 - val_mean_absolute_error: 2.8406\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 2.83718\n",
      "Epoch 349/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8383 - val_mean_absolute_error: 2.8383\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 2.83718\n",
      "Epoch 350/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8585 - mean_absolute_error: 2.8585 - val_loss: 2.8478 - val_mean_absolute_error: 2.8478\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 2.83718\n",
      "Epoch 351/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8521 - mean_absolute_error: 2.8521 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 2.83718\n",
      "Epoch 352/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8562 - mean_absolute_error: 2.8562 - val_loss: 2.8536 - val_mean_absolute_error: 2.8536\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 2.83718\n",
      "Epoch 353/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8606 - mean_absolute_error: 2.8606 - val_loss: 2.8401 - val_mean_absolute_error: 2.8401\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 2.83718\n",
      "Epoch 354/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8396 - val_mean_absolute_error: 2.8396\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 2.83718\n",
      "Epoch 355/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8529 - mean_absolute_error: 2.8529 - val_loss: 2.8409 - val_mean_absolute_error: 2.8409\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 2.83718\n",
      "Epoch 356/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8482 - val_mean_absolute_error: 2.8482\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 2.83718\n",
      "Epoch 357/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8545 - mean_absolute_error: 2.8545 - val_loss: 2.8660 - val_mean_absolute_error: 2.8660\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 2.83718\n",
      "Epoch 358/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8540 - mean_absolute_error: 2.8540 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 2.83718\n",
      "Epoch 359/500\n",
      "2680/2680 [==============================] - 0s 101us/step - loss: 2.8536 - mean_absolute_error: 2.8536 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 2.83718\n",
      "Epoch 360/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8579 - mean_absolute_error: 2.8579 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 2.83718\n",
      "Epoch 361/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 2.83718\n",
      "Epoch 362/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8583 - mean_absolute_error: 2.8583 - val_loss: 2.8387 - val_mean_absolute_error: 2.8387\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 2.83718\n",
      "Epoch 363/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8569 - mean_absolute_error: 2.8569 - val_loss: 2.8454 - val_mean_absolute_error: 2.8454\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 2.83718\n",
      "Epoch 364/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8542 - mean_absolute_error: 2.8542 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 2.83718\n",
      "Epoch 365/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8487 - val_mean_absolute_error: 2.8487\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 2.83718\n",
      "Epoch 366/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8596 - mean_absolute_error: 2.8596 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 2.83718\n",
      "Epoch 367/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8607 - mean_absolute_error: 2.8607 - val_loss: 2.8381 - val_mean_absolute_error: 2.8381\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 2.83718\n",
      "Epoch 368/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8402 - val_mean_absolute_error: 2.8402\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 2.83718\n",
      "Epoch 369/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8664 - val_mean_absolute_error: 2.8664\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 2.83718\n",
      "Epoch 370/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8611 - mean_absolute_error: 2.8611 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 2.83718\n",
      "Epoch 371/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8632 - mean_absolute_error: 2.8632 - val_loss: 2.8450 - val_mean_absolute_error: 2.8450\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 2.83718\n",
      "Epoch 372/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8614 - mean_absolute_error: 2.8614 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 2.83718\n",
      "Epoch 373/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8399 - val_mean_absolute_error: 2.8399\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 2.83718\n",
      "Epoch 374/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8415 - val_mean_absolute_error: 2.8415\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 2.83718\n",
      "Epoch 375/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8450 - val_mean_absolute_error: 2.8450\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 2.83718\n",
      "Epoch 376/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8455 - val_mean_absolute_error: 2.8455\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 2.83718\n",
      "Epoch 377/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8450 - val_mean_absolute_error: 2.8450\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 2.83718\n",
      "Epoch 378/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8570 - mean_absolute_error: 2.8570 - val_loss: 2.8386 - val_mean_absolute_error: 2.8386\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 2.83718\n",
      "Epoch 379/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8486 - val_mean_absolute_error: 2.8486\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 2.83718\n",
      "Epoch 380/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8661 - mean_absolute_error: 2.8661 - val_loss: 2.8383 - val_mean_absolute_error: 2.8383\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 2.83718\n",
      "Epoch 381/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8654 - mean_absolute_error: 2.8654 - val_loss: 2.8532 - val_mean_absolute_error: 2.8532\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 2.83718\n",
      "Epoch 382/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 2.83718\n",
      "Epoch 383/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8388 - val_mean_absolute_error: 2.8388\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 2.83718\n",
      "Epoch 384/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8563 - mean_absolute_error: 2.8563 - val_loss: 2.8385 - val_mean_absolute_error: 2.8385\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 2.83718\n",
      "Epoch 385/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8606 - mean_absolute_error: 2.8606 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 2.83718\n",
      "Epoch 386/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8614 - val_mean_absolute_error: 2.8614\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 2.83718\n",
      "Epoch 387/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8379 - val_mean_absolute_error: 2.8379\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 2.83718\n",
      "Epoch 388/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 2.83718\n",
      "Epoch 389/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8418 - val_mean_absolute_error: 2.8418\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 2.83718\n",
      "Epoch 390/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8537 - mean_absolute_error: 2.8537 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 2.83718\n",
      "Epoch 391/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8431 - val_mean_absolute_error: 2.8431\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 2.83718\n",
      "Epoch 392/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8522 - mean_absolute_error: 2.8522 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 2.83718\n",
      "Epoch 393/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8500 - val_mean_absolute_error: 2.8500\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 2.83718\n",
      "Epoch 394/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8587 - mean_absolute_error: 2.8587 - val_loss: 2.8431 - val_mean_absolute_error: 2.8431\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 2.83718\n",
      "Epoch 395/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8578 - mean_absolute_error: 2.8578 - val_loss: 2.8635 - val_mean_absolute_error: 2.8635\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 2.83718\n",
      "Epoch 396/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8385 - val_mean_absolute_error: 2.8385\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 2.83718\n",
      "Epoch 397/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8552 - mean_absolute_error: 2.8552 - val_loss: 2.8470 - val_mean_absolute_error: 2.8470\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 2.83718\n",
      "Epoch 398/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 2.8517 - val_mean_absolute_error: 2.8517\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 2.83718\n",
      "Epoch 399/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8522 - mean_absolute_error: 2.8522 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 2.83718\n",
      "Epoch 400/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8401 - val_mean_absolute_error: 2.8401\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 2.83718\n",
      "Epoch 401/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8551 - mean_absolute_error: 2.8551 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 2.83718\n",
      "Epoch 402/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8447 - val_mean_absolute_error: 2.8447\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 2.83718\n",
      "Epoch 403/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8593 - mean_absolute_error: 2.8593 - val_loss: 2.8465 - val_mean_absolute_error: 2.8465\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 2.83718\n",
      "Epoch 404/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8592 - mean_absolute_error: 2.8592 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 2.83718\n",
      "Epoch 405/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8674 - mean_absolute_error: 2.8674 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 2.83718\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8527 - mean_absolute_error: 2.8527 - val_loss: 2.8501 - val_mean_absolute_error: 2.8501\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 2.83718\n",
      "Epoch 407/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8560 - mean_absolute_error: 2.8560 - val_loss: 2.8402 - val_mean_absolute_error: 2.8402\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 2.83718\n",
      "Epoch 408/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8558 - mean_absolute_error: 2.8558 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 2.83718\n",
      "Epoch 409/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8606 - mean_absolute_error: 2.8606 - val_loss: 2.8416 - val_mean_absolute_error: 2.8416\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 2.83718\n",
      "Epoch 410/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8521 - mean_absolute_error: 2.8521 - val_loss: 2.8478 - val_mean_absolute_error: 2.8478\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 2.83718\n",
      "Epoch 411/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8527 - mean_absolute_error: 2.8527 - val_loss: 2.8425 - val_mean_absolute_error: 2.8425\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 2.83718\n",
      "Epoch 412/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8565 - val_mean_absolute_error: 2.8565\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 2.83718\n",
      "Epoch 413/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8588 - mean_absolute_error: 2.8588 - val_loss: 2.8569 - val_mean_absolute_error: 2.8569\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 2.83718\n",
      "Epoch 414/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8396 - val_mean_absolute_error: 2.8396\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 2.83718\n",
      "Epoch 415/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8462 - val_mean_absolute_error: 2.8462\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 2.83718\n",
      "Epoch 416/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8581 - mean_absolute_error: 2.8581 - val_loss: 2.8387 - val_mean_absolute_error: 2.8387\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 2.83718\n",
      "Epoch 417/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8402 - val_mean_absolute_error: 2.8402\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 2.83718\n",
      "Epoch 418/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8584 - mean_absolute_error: 2.8584 - val_loss: 2.8417 - val_mean_absolute_error: 2.8417\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 2.83718\n",
      "Epoch 419/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8548 - mean_absolute_error: 2.8548 - val_loss: 2.8392 - val_mean_absolute_error: 2.8392\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 2.83718\n",
      "Epoch 420/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8574 - mean_absolute_error: 2.8574 - val_loss: 2.8376 - val_mean_absolute_error: 2.8376\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 2.83718\n",
      "Epoch 421/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8542 - mean_absolute_error: 2.8542 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 2.83718\n",
      "Epoch 422/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8556 - mean_absolute_error: 2.8556 - val_loss: 2.8508 - val_mean_absolute_error: 2.8508\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 2.83718\n",
      "Epoch 423/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8586 - mean_absolute_error: 2.8586 - val_loss: 2.8425 - val_mean_absolute_error: 2.8425\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 2.83718\n",
      "Epoch 424/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8457 - val_mean_absolute_error: 2.8457\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 2.83718\n",
      "Epoch 425/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8539 - mean_absolute_error: 2.8539 - val_loss: 2.8422 - val_mean_absolute_error: 2.8422\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 2.83718\n",
      "Epoch 426/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8611 - mean_absolute_error: 2.8611 - val_loss: 2.8382 - val_mean_absolute_error: 2.8382\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 2.83718\n",
      "Epoch 427/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8482 - mean_absolute_error: 2.8482 - val_loss: 2.8430 - val_mean_absolute_error: 2.8430\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 2.83718\n",
      "Epoch 428/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8592 - mean_absolute_error: 2.8592 - val_loss: 2.8399 - val_mean_absolute_error: 2.8399\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 2.83718\n",
      "Epoch 429/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8603 - mean_absolute_error: 2.8603 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 2.83718\n",
      "Epoch 430/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8565 - mean_absolute_error: 2.8565 - val_loss: 2.8378 - val_mean_absolute_error: 2.8378\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 2.83718\n",
      "Epoch 431/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8564 - mean_absolute_error: 2.8564 - val_loss: 2.8413 - val_mean_absolute_error: 2.8413\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 2.83718\n",
      "Epoch 432/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8526 - mean_absolute_error: 2.8526 - val_loss: 2.8466 - val_mean_absolute_error: 2.8466\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 2.83718\n",
      "Epoch 433/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8570 - mean_absolute_error: 2.8570 - val_loss: 2.8387 - val_mean_absolute_error: 2.8387\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 2.83718\n",
      "Epoch 434/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8429 - val_mean_absolute_error: 2.8429\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 2.83718\n",
      "Epoch 435/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8570 - mean_absolute_error: 2.8570 - val_loss: 2.8380 - val_mean_absolute_error: 2.8380\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 2.83718\n",
      "Epoch 436/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8535 - mean_absolute_error: 2.8535 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 2.83718\n",
      "Epoch 437/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8531 - mean_absolute_error: 2.8531 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 2.83718\n",
      "Epoch 438/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 2.83718\n",
      "Epoch 439/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8554 - mean_absolute_error: 2.8554 - val_loss: 2.8462 - val_mean_absolute_error: 2.8462\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 2.83718\n",
      "Epoch 440/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8631 - mean_absolute_error: 2.8631 - val_loss: 2.8448 - val_mean_absolute_error: 2.8448\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 2.83718\n",
      "Epoch 441/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8524 - mean_absolute_error: 2.8524 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 2.83718\n",
      "Epoch 442/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8560 - mean_absolute_error: 2.8560 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 2.83718\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 2.83718\n",
      "Epoch 444/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8542 - mean_absolute_error: 2.8542 - val_loss: 2.8486 - val_mean_absolute_error: 2.8486\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 2.83718\n",
      "Epoch 445/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8407 - val_mean_absolute_error: 2.8407\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 2.83718\n",
      "Epoch 446/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8442 - val_mean_absolute_error: 2.8442\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 2.83718\n",
      "Epoch 447/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8554 - mean_absolute_error: 2.8554 - val_loss: 2.8438 - val_mean_absolute_error: 2.8438\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 2.83718\n",
      "Epoch 448/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8570 - mean_absolute_error: 2.8570 - val_loss: 2.8404 - val_mean_absolute_error: 2.8404\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 2.83718\n",
      "Epoch 449/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8571 - mean_absolute_error: 2.8571 - val_loss: 2.8380 - val_mean_absolute_error: 2.8380\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 2.83718\n",
      "Epoch 450/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8535 - mean_absolute_error: 2.8535 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 2.83718\n",
      "Epoch 451/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8422 - val_mean_absolute_error: 2.8422\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 2.83718\n",
      "Epoch 452/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8519 - mean_absolute_error: 2.8519 - val_loss: 2.8415 - val_mean_absolute_error: 2.8415\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 2.83718\n",
      "Epoch 453/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8523 - mean_absolute_error: 2.8523 - val_loss: 2.8380 - val_mean_absolute_error: 2.8380\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 2.83718\n",
      "Epoch 454/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8525 - mean_absolute_error: 2.8525 - val_loss: 2.8412 - val_mean_absolute_error: 2.8412\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 2.83718\n",
      "Epoch 455/500\n",
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 2.83718\n",
      "Epoch 456/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 2.83718\n",
      "Epoch 457/500\n",
      "2680/2680 [==============================] - 0s 99us/step - loss: 2.8535 - mean_absolute_error: 2.8535 - val_loss: 2.8490 - val_mean_absolute_error: 2.8490\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 2.83718\n",
      "Epoch 458/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8626 - mean_absolute_error: 2.8626 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 2.83718\n",
      "Epoch 459/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8535 - mean_absolute_error: 2.8535 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 2.83718\n",
      "Epoch 460/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8588 - mean_absolute_error: 2.8588 - val_loss: 2.8534 - val_mean_absolute_error: 2.8534\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 2.83718\n",
      "Epoch 461/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8581 - mean_absolute_error: 2.8581 - val_loss: 2.8385 - val_mean_absolute_error: 2.8385\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 2.83718\n",
      "Epoch 462/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8557 - mean_absolute_error: 2.8557 - val_loss: 2.8377 - val_mean_absolute_error: 2.8377\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 2.83718\n",
      "Epoch 463/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 2.83718\n",
      "Epoch 464/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8515 - mean_absolute_error: 2.8515 - val_loss: 2.8931 - val_mean_absolute_error: 2.8931\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 2.83718\n",
      "Epoch 465/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8620 - mean_absolute_error: 2.8620 - val_loss: 2.8423 - val_mean_absolute_error: 2.8423\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 2.83718\n",
      "Epoch 466/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8617 - mean_absolute_error: 2.8617 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 2.83718\n",
      "Epoch 467/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 2.83718\n",
      "Epoch 468/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8529 - mean_absolute_error: 2.8529 - val_loss: 2.8797 - val_mean_absolute_error: 2.8797\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 2.83718\n",
      "Epoch 469/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8643 - mean_absolute_error: 2.8643 - val_loss: 2.8422 - val_mean_absolute_error: 2.8422\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 2.83718\n",
      "Epoch 470/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8639 - mean_absolute_error: 2.8639 - val_loss: 2.8398 - val_mean_absolute_error: 2.8398\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 2.83718\n",
      "Epoch 471/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8542 - mean_absolute_error: 2.8542 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 2.83718\n",
      "Epoch 472/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8568 - mean_absolute_error: 2.8568 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 2.83718\n",
      "Epoch 473/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8563 - mean_absolute_error: 2.8563 - val_loss: 2.8531 - val_mean_absolute_error: 2.8531\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 2.83718\n",
      "Epoch 474/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8590 - mean_absolute_error: 2.8590 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 2.83718\n",
      "Epoch 475/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8581 - mean_absolute_error: 2.8581 - val_loss: 2.8424 - val_mean_absolute_error: 2.8424\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 2.83718\n",
      "Epoch 476/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8532 - mean_absolute_error: 2.8532 - val_loss: 2.8438 - val_mean_absolute_error: 2.8438\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 2.83718\n",
      "Epoch 477/500\n",
      "2680/2680 [==============================] - 0s 97us/step - loss: 2.8628 - mean_absolute_error: 2.8628 - val_loss: 2.8403 - val_mean_absolute_error: 2.8403\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 2.83718\n",
      "Epoch 478/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8555 - mean_absolute_error: 2.8555 - val_loss: 2.8606 - val_mean_absolute_error: 2.8606\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 2.83718\n",
      "Epoch 479/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8547 - mean_absolute_error: 2.8547 - val_loss: 2.8475 - val_mean_absolute_error: 2.8475\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 2.83718\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2680/2680 [==============================] - 0s 98us/step - loss: 2.8529 - mean_absolute_error: 2.8529 - val_loss: 2.8484 - val_mean_absolute_error: 2.8484\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 2.83718\n",
      "Epoch 481/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8530 - mean_absolute_error: 2.8530 - val_loss: 2.8913 - val_mean_absolute_error: 2.8913\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 2.83718\n",
      "Epoch 482/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8550 - mean_absolute_error: 2.8550 - val_loss: 2.8374 - val_mean_absolute_error: 2.8374\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 2.83718\n",
      "Epoch 483/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8534 - mean_absolute_error: 2.8534 - val_loss: 2.8393 - val_mean_absolute_error: 2.8393\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 2.83718\n",
      "Epoch 484/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8587 - mean_absolute_error: 2.8587 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 2.83718\n",
      "Epoch 485/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8396 - val_mean_absolute_error: 2.8396\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 2.83718\n",
      "Epoch 486/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8544 - mean_absolute_error: 2.8544 - val_loss: 2.8656 - val_mean_absolute_error: 2.8656\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 2.83718\n",
      "Epoch 487/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8549 - mean_absolute_error: 2.8549 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 2.83718\n",
      "Epoch 488/500\n",
      "2680/2680 [==============================] - 0s 93us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8433 - val_mean_absolute_error: 2.8433\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 2.83718\n",
      "Epoch 489/500\n",
      "2680/2680 [==============================] - 0s 100us/step - loss: 2.8526 - mean_absolute_error: 2.8526 - val_loss: 2.8384 - val_mean_absolute_error: 2.8384\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 2.83718\n",
      "Epoch 490/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8546 - mean_absolute_error: 2.8546 - val_loss: 2.8432 - val_mean_absolute_error: 2.8432\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 2.83718\n",
      "Epoch 491/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8532 - mean_absolute_error: 2.8532 - val_loss: 2.8373 - val_mean_absolute_error: 2.8373\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 2.83718\n",
      "Epoch 492/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8538 - mean_absolute_error: 2.8538 - val_loss: 2.8501 - val_mean_absolute_error: 2.8501\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 2.83718\n",
      "Epoch 493/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8398 - val_mean_absolute_error: 2.8398\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 2.83718\n",
      "Epoch 494/500\n",
      "2680/2680 [==============================] - 0s 92us/step - loss: 2.8553 - mean_absolute_error: 2.8553 - val_loss: 2.8476 - val_mean_absolute_error: 2.8476\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 2.83718\n",
      "Epoch 495/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8543 - mean_absolute_error: 2.8543 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 2.83718\n",
      "Epoch 496/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8559 - mean_absolute_error: 2.8559 - val_loss: 2.8433 - val_mean_absolute_error: 2.8433\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 2.83718\n",
      "Epoch 497/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8527 - mean_absolute_error: 2.8527 - val_loss: 2.8372 - val_mean_absolute_error: 2.8372\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 2.83718\n",
      "Epoch 498/500\n",
      "2680/2680 [==============================] - 0s 95us/step - loss: 2.8602 - mean_absolute_error: 2.8602 - val_loss: 2.8582 - val_mean_absolute_error: 2.8582\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 2.83718\n",
      "Epoch 499/500\n",
      "2680/2680 [==============================] - 0s 96us/step - loss: 2.8540 - mean_absolute_error: 2.8540 - val_loss: 2.8656 - val_mean_absolute_error: 2.8656\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 2.83718\n",
      "Epoch 500/500\n",
      "2680/2680 [==============================] - 0s 94us/step - loss: 2.8596 - mean_absolute_error: 2.8596 - val_loss: 2.8375 - val_mean_absolute_error: 2.8375\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 2.83718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f78cc8e4358>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(X_train1, y_train1, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wights file of the best model :\n",
    "# wights_file = 'Weights-478--18738.19831.hdf5' # choose the best checkpoint \n",
    "# NN_model.load_weights(wights_file) # load it\n",
    "\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_submission(prediction, sub_name):\n",
    "#   my_submission = pd.DataFrame({'Id':pd.read_csv('test.csv').Id,'SalePrice':prediction})\n",
    "#   my_submission.to_csv('{}.csv'.format(sub_name),index=False)\n",
    "#   print('A submission file has been made')\n",
    "\n",
    "predictions = NN_model.predict(X_test1)\n",
    "# make_submission(predictions[:,0],'submission(NN).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.861867],\n",
       "       [15.861867],\n",
       "       [15.861867],\n",
       "       ...,\n",
       "       [15.861867],\n",
       "       [15.861867],\n",
       "       [15.861867]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# rms = sqrt(mean_squared_error(predictions, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1173229900176835"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('sample_submission.csv')\n",
    "# df_sub = pd.DataFrame()\n",
    "# df_sub['id'] = sub['id']\n",
    "\n",
    "temp = np.expm1(y_test1)\n",
    "#print(df_sub['revenue'])\n",
    "# df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26828364.99999999, 12368233.99999999, 54215416.        , ...,\n",
       "       28399999.99999998,   115860.        ,   243000.        ])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23218946.],\n",
       "       [23218946.],\n",
       "       [23218946.],\n",
       "       ...,\n",
       "       [23218946.],\n",
       "       [23218946.],\n",
       "       [23218946.]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(predictions)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.10497032, 16.33064205, 17.80847587, ..., 17.16189974,\n",
       "       11.66014648, 12.40082084])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.861867],\n",
       "       [15.861867],\n",
       "       [15.861867],\n",
       "       ...,\n",
       "       [15.861867],\n",
       "       [15.861867],\n",
       "       [15.861867]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
